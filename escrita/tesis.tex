\documentclass[a4paper,12pt,spanish]{book}
%\usepackage[utf8]{inputenc}
\usepackage[utf8x]{inputenc}
\usepackage{url}
\usepackage{makeidx}
\usepackage[procnames]{listings}
\usepackage{color}
\usepackage{graphicx} % graficos
\usepackage[spanish]{babel}



\iffalse
\title{Transferencia de Estilo en Fotografias utilizando Redes Neuronales Convolucionales}   %note \\[1ex] is a line break in the title

\author{Wolfmann, Ariel Mauricio}             %your name
\college{Facultad de Matemática, Astronomía y Física\\[1ex]
		}  %your college
\university{Universidad Nacional de Córdoba}

%\renewcommand{\submittedtext}{change the default text here if needed}
%\degree{Licenciada en Ciencias de la Computación}     %the degree
\directors{Sanchez, Jorge}
\fi

\makeindex



\begin{document}
\definecolor{keywords}{RGB}{255,0,90}
\definecolor{comments}{RGB}{0,0,113}
\definecolor{red}{RGB}{160,0,0}
\definecolor{green}{RGB}{0,150,0}

\lstset{language=Python, 
        basicstyle=\ttfamily\small, 
        keywordstyle=\color{keywords},
        commentstyle=\color{comments},
        stringstyle=\color{red},
        showstringspaces=false,
        identifierstyle=\color{green},
        procnamekeys={def,class}}


\begin{titlepage}
  \begin{center}
  \vspace*{1in}
    \begin{Huge}
    \textbf{Trabajo Final}\\
    \textbf{Transferencia de Estilo en Fotografias utilizando Redes Neuronales Convolucionales} \\
    \end{Huge}
  \end{center}
  \begin{center}
    \begin{large}
      \vspace*{1in}
      Autor: Wolfmann, Ariel Mauricio\\
      Director: Sanchez, Jorge\\
    \end{large}
    \vspace*{0.15in}
     Marzo de 2017\\
    \vspace*{0.15in}
    Universidad Nacional de Córdoba\\
    \vspace*{0.15in}
    Facultad de Matemática, Astronomía y Física\\
    \vspace*{0.6in}
  \end{center}
\end{titlepage}

\pagebreak

\iffalse
\maketitle                  % create a title page from the preamble info
\include{abstract}          % include the abstract
\include{dedication}        % include a dedication.tex file
\include{acknowlegements}   % include an acknowledgements.tex file

\begin{romanpages}          % start roman page numbering
\tableofcontents            % generate and include a table of contents
\listoffigures              % generate and include a list of figures
\end{romanpages}            % end roman page numbering
\fi

\tableofcontents 

\chapter{INTRODUCCION}
  \paragraph{Contexto}
    En los ultimos años las fotografias estan cada vez mas pasando a ser un virtual en lugar de fisico, de la mano del gran aumento en el uso de los dispositivos moviles 
    cualquier persona puede tomar miles fotografias en un instante de tiempo, y compartirla en las redes sociales.
    A partir de esto, se han desarrollado muchas aplicaciones entorno a las fotografias, ya sea desde redes sociales masivamente utilizadas, hasta aplicaciones que aplican efectos o filtros 
    a la fotografia para transformarla en un retrato en blanco y negro o sepia por ejemplo.
    Muy recientemente se han comenzado a desarrollar aplicaciones que logran transferir el estilo de una obra de arte a una fotografia. Esto es posible gracias al incremento 
    del poder de cómputo y al decrecimiento del precio de los nuevos dispositivos, ya que las técnicas computacionales empleadas para esto, requieren un cómputo mucho mas complejo.
    Las principal herramienta utilizada para poder llevar esta tarea a cabo son Redes Neuronales Convolucionales, provenientes del area de  
    Inteligencia Artificial y Aprendizaje Automatico, que al aplicarse al area de Vision por Computadoras han logrado resultados absolutamente disruptivos, 
    comparado a los ultimos avances que se venian obteniendo en el area, principalmente para la clasificacion de imagenes, detección y reconocimiento de objetos.
    Por mencionar otro ejemplo de gran investigacion en la actualidad, los autos que se conducen por si solos, emplean estas tecnicas para lograrlo.
  \paragraph{Motivación}
    En lo que respecta al área de visión por computadoras, una imagen es representada por un vector de 2 dimensiones donde cada valor representa la intensidad captada por un sensor 
    de un determinado punto espacial, representados como píxeles. La representación de los píxeles es muy sensible a cambios en la iluminación, ángulo, contraste y tamaño que pueda existir.
    Existen articulos de investigación en los cuales se definen algoritmos para la transferencia de estilos artisticos en fotografias, que se basan en modelos estocasticos, 
    los cuales requieren una gran cantidad de hiperparámetros predefinidos empiricamente, es decir parámetros que deben ser fijados previo a la ejecución del algoritmo que dependen 
    de la elección propia del usuario, pero que influyen en gran manera sobre el resultado.
    El principal objetivo de este trabajo es poder realizar una elección inteligente de uno de los principales hiperparámetros como lo es el número de iteraciones 
    que debe realizar el algoritmo hasta obtener un resultado interesante.
    Para poder determinar cuando un resultado logra ser aceptable es necesario definir una métrica para esto.
    Debido a que las obras de arte, sueles calificadas con metricas cualitativas y no tanto cuantitativas, se decidió utilizar otra red neuronal convolucional, 
    entrenada especialmente para reconocer estilos artisticos y en base a los resultados que arroja se define si el numero de iteraciones es suficiente para generar el resultado final 
    o es necesario continuar iterando.
  \paragraph{Estructura del trabajo}
    A lo largo de este trabajo se hará un recorrido por los principales conceptos para comprender tanto el problema como la solución y las tecnicas empleadas.
    El capitulo 2 contendrá el marco teorico y cuestiones formales requeridas, principalmente orientado al aprendizaje Automatico y a las redes neuronales.
    En el capitulo 3 se hara un recorrido por los principales articulos de investigación y los algoritmos alli definidos para las tecnicas de transferencia y reconocimiento de estilos artisticos.
    Para luego abordar en detalle la solución propuesta, junto con un analisis y evaluacion empirica de la misma.
    En el capitulo 4 será quien contenga los experimentos realizado y los resultados obtenidos, para finalmente en el capitulo 5 establecer una conclusión acerca del trabajo realizado, 
    junto con las perspectivas y posibles tareas a futuro.

Para introducir al lector en el tema, a continuación se muestran algunos ejemplos de resultados generados transfiriendo el estilo artistico a fotografias:
ADJUNTAR EJEMPLOS

\iffalse
Tener en cuenta:
In fine art, especially painting, humans have mastered the skill to create unique
visual experiences through composing a complex interplay between the con-
tent and style of an image. Thus far the algorithmic basis of this process is
unknown and there exists no artificial system with similar capabilities. How-
ever, in other key areas of visual perception such as object and face recognition
near-human performance was recently demonstrated by a class of biologically
inspired vision models called Deep Neural Networks. 1, 2 Here we introduce an
artificial system based on a Deep Neural Network that creates artistic images
of high perceptual quality. The system uses neural representations to sepa-
rate and recombine content and style of arbitrary images, providing a neural
algorithm for the creation of artistic images. Moreover, in light of the strik-
ing similarities between performance-optimised artificial neural networks and
biological vision, 3–7 our work offers a path forward to an algorithmic under-
standing of how humans create and perceive artistic imagery.
\fi

\chapter{MARCO TEORICO}

%Material para revisar
%http://cs231n.github.io/
%Capítulo 2 del Mitchel (1997), Capítulos 3 y 6 del Mitchel (1997)
%Wolpert, D.H., Macready, W.G. (1997), "No Free Lunch Theorems for Optimization," IEEE Transactions on Evolutionary Computation 1, 67
%http://en.wikipedia.org/wiki/Inductive_bias
%http://en.wikipedia.org/wiki/Overfitting
%http://en.wikipedia.org/wiki/SURF
%Capítulo 5 del Marlsand (2009) "Machine Learning, an Algorithmic Perspective"
%Capítulo 5 del Smola & Vishwanathan (2008) "Introduction to Machine Learning"
%http://en.wikipedia.org/wiki/Logistic_regression
%http://en.wikipedia.org/wiki/Linear_regression
%Capítulo 13 del Owen et al. (2012), Capítulo 2 y 4 del Owen et al. (2012)
%http://ufal.mff.cuni.cz/~zabokrtsky/courses/npfl104/html/feature_engineering.pdf
%http://aprendizajengrande.net/cronograma.html
%http://www.deeplearningbook.org/
%Bishop



  \section{Aprendizaje Automatico}
%https://en.wikipedia.org/wiki/Machine_learning
    \subsection{Introduccion}
      El Aprendizaje Automatico (o machine learning, por su denominación en inglés) es un subcampo de las ciencias de la computacion que le otorga a las computadoras la habilidad de aprender o inferir reglas que no fueron explicitamente programadas.
      Surge desde el estudio de reconocimiento de patrones, y el aprendizaje computacional, provenientes de la Inteligencia aritificial, este campo explora el estudio y la construccion de algoritmos
      que pueden aprender y realizar predicciones a partir de datos. En base a las reglas determinadas explicitamente en el programa y los datos de ejemplo, se crea un modelo que intenta predecir
      características de un dato nuevo. Este tipo de algoritmos tienen su enfoque basado en los datos.\\
      Tom M. Mitchell elaboró una definición más formal de este concepto de aprendizaje: “se dice que un programa de computadora aprende de una experiencia E con respecto a una clase 
      de tarea T y medición de desempeño P, si su desempeño en la tarea T, medido por P, mejora con la experiencia E” [Mitchell,1997].\\
      Algoritmos con error intrínseco
      ¿Qué hacer con un programa que falla aún habiendo sido programado correctamente?
      No todos los problemas pueden ser abordados vía Aprendizaje Automático
      Incluir el error dentro del modelo de uso

    \subsection{Datos}
      Al ser un area que tiene su enfoque basado en los datos de entrada, estos pasan a cumplir un rol fundamental en el desarrollo del algoritmo, por ello es necesario que 
      esten los mas limpios y puros posible, es decir lograr obtener un conjunto de datos utiles a los que se le puedan aplicar algoritmos de aprendizaje automatico, 
      motivo por el cual en muchas ocasiones se realiza una fase de preprocesamiento de datos, la cual puede llegar a ser la etapa que mas trabajo requiera del proceso completo. 


    \subsection{Ciclo del Aprendizaje Automático}
      \begin{itemize}
	\item Recopilación de datos
	  El recopilado de datos es crucial, puede requerir mucho esfuerzo y cambio de procesos complejos, 
	  Anotación, Muchas veces la clase objetivo tiene que ser calculada a mano por grupos de personas designadas para la tarea
	\item Definicion de caracteristicas
	\item Entrenamiento
	  Antes de comenzar el entrenamiento el conjunto de datos se divide en 2 subconjuntos, un conjunto de datos de entrenamiento y un conjunto de datos de prueba. 
	  Para entrenar el modelo solo se utiliza el conjunto de datos de entrenamiento, el conjunto de datos de prueba se separa.
	  Determinar la estructura del modelo de aprendizaje, en base al tipo de problema y a la forma en la que se representan las caracteristicas de los datos.
	  En algunos modelos, a partir del conjunto de datos de entrenamiento, se realiza otra particion de un pequeño subconjunto llamado conjunto de datos de validacion, este conjunto sirve 
	  para afinar ciertos hiperparametros del modelo.
	  Entrenar el modelo elegido sobre el conjunto de datos de entrenamiento
	\item Evaluacion
	  Se aplica el modelo entrenado a los datos del conjunto de prueba, y se aplican metricas para poder establecer que tan bien predice el modelo entrenado para datos nunca antes vistos.
    \end{itemize}


    \subsection{Características para el Aprendizaje}
      Para que un modelo pueda aprender, es necesario definir las caracteristicas (features en inglés) que este deberá aprender a partir de las instancias de entrenamiento, segun el tipo de dato, estas
      caracteristicas iran variando.
      \subsubsection{Representando una instancia}
	\begin{itemize}
	  \item Representaciones planas
	  \item Nuevos sistemas permiten representar árboles o grafos
	  \item Tipos de features: booleanas (true, false), numéricas (4, 1, -5), de punto flotante (0.5, 1, 9.2), enumeraciones (rojo,azul,verde,amarillo)
	  \item Representando valores complejos
	  \item Conjuntos
	    \subitem Features binarios por la presencia de cada elemento
	    \subitem Clase objetivo de conjuntos: entrenar un sistema independiente por cada elemento
	\end{itemize}
      \subsubsection{Representando un texto}
	\begin{itemize}
	  \item Bag of words
	  \item Una feature por palabra, indicando si la palabra aparece en el texto o no (binaria) o cuantas veces aparece (numérico)
	  \item Puede extenderse a pares de palabras (bigram model) o más
	  \item Sólo se pueden usar palabras vistas durante el entrenamiento
	\end{itemize}
	\subsubsection{Representando imágenes}
	  Es un campo de investigación que en la actualidad se encuentra muy activo. El método más sencillo es usar el valor de los píxeles directamente, aunque este no generaliza muy bien
	  Pero puede mejorar utilizando transformaciones algorítmicas del conjunto de entrenamiento el siguiente paso seria tomar el promedio sobre pequeños cuadrados de la imágen.
	  Necesitamos de alguna funcion compleja que comprenda el significado de la imágen más allá de la representación numérica de la misma.
	  A lo largo del desarrollo de la visión por computadora se distinguen dos enfoques para la generacion de descriptores capaces de reconocer caracteristicas de una imagen: 
	  El enfoque basado en técnicas superficiales (o “shallow” en inglés) y el enfoque de aprendizaje no-supervisado.
	  \paragraph{Enfoque Superficial}
	    El enfoque superficial responde a la manera tradicional de hacer visión por computadoras. Se busca generar una representación invariante a la posición, iluminación, fondo,
	    etc. utilizando principalmente técnicas estadísticas a partir de conocimiento anterior del objeto y del contexto. Los descriptores superficiales son diseñados a mano a 
	    partir de características físicas, hipótesis y observaciones. El enfoque entonces no aprende features de los objetos sino que se procesa la imágen de interés con un 
	    extractor de features prefijadas y luego se pasa la nueva representación a un clasificador entrenable. Los métodos más utilizadas que generan este tipo de descriptores son SIFT, SURF y Vectores Fisher.
	  \paragraph{Enfoque de Aprendizaje No Supervisado} 
	    La filosofía de estas técnicas se basa en la hipótesis de “un único algoritmo de aprendizaje”: El cerebro usa esencialmente el mismo algoritmo para comprender diferentes formas de entrada. 
	    Es entonces que en este enfoque se contempla que la complejidad de la percepción no está en el algoritmo ni en las estructuras de aprendizaje, sino en los datos. 
	    El enfoque no supervisado consiste de técnicas, algoritmos y estructuras inspiradas en el cerebro que son capaces de aprender features por sí mismas, 
	    en lugar de que sean diseñadas a mano y prefijadas en el detector. El problema asociado a esto es que no sabemos qué features el modelo aprende durante el entrenamiento.
	    Las estructuras de aprendizaje no-supervisado de features contemplan el concepto heredado de la neurobiología de que las features son jerárquicas: 
	    desde features de bajo nivel como bordes y contornos, hasta estructuras y objetos. Las Redes Neuronales Convolucionales soportan el aprendizaje de este tipo features 
	    y es el modelo que analizaremos posteriormente en este trabajo.


      \subsubsection{Normalización}
	Algunos algoritmos de aprendizaje funcionan mejor si los valores de las features de entrada tienen media cero y dispersión 1
	Muchas veces se agrega la versión normalizada del feature como un feature extra y se deja al algoritmo de aprendizaje que decida qué feature es más útil.
	El valor absoluto de un feature muchas veces contiene información relevante

      \subsubsection{Reducción de dimensionalidad}
	Selección de features es una técnica de reducción de dimensionalidad
	Otras involucran todas las features a la vez y generan un cambio de coordenadas, de un espacio mayo a uno menor
	Una muy utilizada es descomposición en valores singulares (SVD) o también llamada análisis de componentes principales (PCA)

	Véase http://infolab.stanford.edu/~ullman/mmds/ch11.pdf


      \subsection{Modelos}

	¿Qué es un modelo?
	“Un ente que aprende que no asume nada acerca de la identidad del concepto objetivo no tiene ninguna base racional para clasificar cosas que nunca vio.”
	Mitchel (1997)
	El principal objetivo de un sistema de aprendizaje es generalizar desde su experiencia o conocimiento previo. Generalizar en este contexto es la habilidad del sistema de realizar
	predicciones con precision sobre un ejemplo nuevo no visto antes, luego de aprender sobre el conjunto de entrenamiento. Los ejemplos de entrenamiento provienen de un espacio 
	con probabilidad de distribución desconocida del cual es considerado representativo. El sistema de aprendizaje debe construir un modelo sobre el espacio total que le permite realizar
	predicciones lo suficientemente precisas sobre nuevos ejemplos.
	\begin{itemize}
	  \item Los modelos capturan la información en los datos de entrada (o en los datos en general, en aprendizaje no supervisado)
	  \item Representan la forma de ver el mundo que permite extrapolar cuando se observan nuevos datos (nunca vistos).
	  \item Los modelos pueden ser matemáticamente bien formados (estadísticos) o simplemente algoritmicos (cascadas de if-then-else).
	  \item El modelo como código objeto: Diferenciamos el modelo del algoritmo usado para obtener el modelo.
	\end{itemize}

      \subsection{Evaluación}

	\subsubsection {Evaluando modelos}
	  \begin{itemize}
	    \item Medir cuantas veces un sistema devuelve la respuesta correcta (“exactitud/accuracy”) no es suficiente
	    \item Muchos problemas de interés práctico tienen un gran sesgo hacia una sola clase (clase de fondo)
	    \item Si el 95% de las veces algo no ocurre, decir que nunca ocurrirá (¡un modelo que no es particularmente muy útil!) se equivocará sólo un 5% del tiempo
	    \item Datos apartados (no entrenar y testear sobre los mismos datos)
	    \item Los datos apartados tienen que ser representativos del problema y la población donde se utilizará el sistema
	  \end{itemize}

	\paragraph {Precision/Recall}
	  \begin{itemize}	
	    \item TP: true positives, los elementos anotados correctos
	    \item FP: false positives, elementos anotados incorrectos
	    \item FN: false negatives, elementos no anotados correctos
	  \end{itemize}
	  ¿Cómo definimos precision/recall?
	  Dos opciones:
	  Acumulamos los TP/FP/FN sobre los distintos conjuntos: promediado micro (micro-averaging)
	  Promediamos los resultados de precision/recall calculado en cada conjunto por separado: promediado macro (macro-averaging)

	\paragraph {Métrica F }
	  Promedio entre precision / recall

	\paragraph {ROC}
	  \begin{itemize}
	    \item Cuando se puede variar Precision/Recall con un parámetro, esto forma una curva
	    \item El área bajo esa curva nos dá la idea de que tan bien funciona un sistema
	    \item Un sistema que funciona todo el tiempo con muy buena precision y recall, tendrá un área muy grande
	    \item Un sistema que tiene gran precision pero clasifica pocas instancias y muy poca precision cuando clasifica muchas tendrá muy poca área
	    \item Promediado micro y macro
	    \item Cuando el sistema se ejecuta sobre varios conjuntos de testeo
	  \end{itemize}

	\paragraph {Trampas de evaluación}
	  Errores comunes de evaluación:
	  \begin{itemize}
	    \item Testear donde se entrenó
	    \item Target leak: una de las features contiene la clase objetivo
	    \item En general, si algo no concuerda, no tiene sentido, hay que investigar
	    \item Posible error de programación en el sistema de testeo
	    \item No quedarse sólo con los números, hacer análisis de errors viendo casos concretos
	    \item Fácil detectar errores de código en el sistema
	  \end{itemize}

	\paragraph {Overfitting}
	  Cuando el sesgo estadísitico disminuye demasiado y la varianza empieza a dispararse

	\paragraph {Cros-validación}
	  Prácticamente como entrenar y testear en los mismo datos
	  datos = {A,B,C}
	  \begin{itemize}
	    \item entrenar en A,B, testear en C
	    \item entrenar en A,C, testear en B
	    \item entrenar en B,C, testear en A
	  \end{itemize}
	  Útil cuando se tienen pocos datos

  \section{Clasificacion de algoritmos de aprendizaje automático}
    Dentro del aprendizaje automático, los algoritmos se pueden clasificar segun la forma en la que aprenden de sus datos:

    \subsection{Aprendizaje No supervisado} 
      \begin{itemize}
	\item La caracteristica principal de este tipo de algoritmos es que los datos de entrenamiento no estan etiquetados
	\item El principal algoritmo de aprendizaje no supervisado es el de Clustering(agrupamiento)
      \end{itemize}
      \subsubsection {Clustering}
	\begin{itemize}
	  \item Consiste en agrupar objetos, de forma tal que los objetos pertenecientes a un mismo grupo son en algun sentido mas similares entre ellos que a los objetos que pertenecen a otro grupo.
	  \item El objetivo de los métodos de clustering es descubrir grupos significativos presentes en los datos.
	  \item El concepto central en clustering es la definición de una función de distancia entre instancias
	  \item Cada definición de distancias induce un agrupamiento de los datos, basado en esa métrica
	  \item La distancia es donde se incorpora la información humana
	\end{itemize}

    \subsection{Aprendizaje semi supervisado}

      Estos algoritmos se caracterizan por utilizar una pequeña cantidad de datos etiquetados y otro gran conjunto de datos no etiquetados
      Principal problema atacado:
      \subsubsection {Recomendación}
	\begin{itemize}
	  \item Un problema en el medio entre supervisado y no supervisado
	  \item Dado un conjunto de personas y objetos, recomendar nuevos objetos similares a los que la persona elige, pero que no conoce
	  \item Amplia utilidad práctica
	  \item Collaborative Filtering
	  \item Filtrar información usando comunidades de personas
	  \item Usuarios, ítems y preferencias
	\end{itemize}
      \paragraph {Recomendación basada en Usuarios}
	\begin{itemize}
	  \item para cada ítem i para el cual el usuario u no tiene preferencia:
	  \item para cada otro usuario v que tiene preferencia por i:
	  \item calcular la similitud s entre u y v
	  \item acumular la preferencia de v por i, pesada por s
	  \item devolver los ítems con mayor preferencia pesada
	\end{itemize}
      \paragraph {Recomendación basada en Ítems}
	\begin{itemize}
	  \item para cada ítem i para el cual el usuario u no tiene preferencia:
	  \item para cada ítem j que u tiene una preferencia:
	  \item calcular la similitud s entre i y j
	  \item acumular la preferencia de u por j, pesada por s
	  \item devolver los ítems con mayor preferencia pesada
	\end{itemize}
    
    \subsection{Aprendizaje por refuerzo}
      El sistema interactua en un ambiente dinamico en el cual debe cumplir un objetivo determinado, el programa va recibiendo retroalimentacion en terminos de premios y castigos mientras 
      recorre el espacio del problema y de esta forma aprende.

    \subsection{Aprendizaje supervisado}
      Los algoritmos de aprendizaje supervisado, consisten en aprender una funcion, a partir de datos de entrenamiento etiquetados. Cada ejemplo del conjunto de entrenamiento suele ser un par
      compuesto de un objeto de entrenamiento(representado por un vector de caracteristicas) y una etiqueta, que seria el valor de salida deseado.
      El problema tipico que se ataca con estos algoritmos es el de clasificación. Clasificacion se define como el problema de identificar a que categoria pertenece una nueva observacion,
      basada en el conjunto de datos de entrenamiento, que contiene observaciones a las cuales se les conoce si categoria.
      Otra opcion es la regresion que en lugar de determinar a que categoria pertenece, define un puntaje de pertenencia a cada categoria.
      El Aprendizaje Automático sin calificar
      \begin{itemize}
	\item Aprender lo que uno ya sabe
	\item Tratar de aprender una función f(x1, …, xn) → y donde
	\item xi son las caracterísita de aprendizaje (features) de entrada
	\item y es la clase objetivo
	\item La clave es extrapolación, queremos que la función generalize a entradas nunca vistas.
	\item Interpolación lineal es en sí una forma de hacer Aprendizaje Automático supervisado.
	\item Una visión como desarrolladores
	\item Entrenamiento/Estimación/“compilación”:
	\item Entrada: vectores de features, incluyendo la clase objetivo
	\item Salida: un modelo entrenado
	\item Ejecución/Predicción/“interpretado”:
	\item Entrada: vectores de features, sin la clase objetivo, más el modelo entrenado
	\item Salida: la clase objetivo predicha
      \end{itemize}
      
      \subsubsection{Clasificacion}

      Ejemplos de algoritmos de clasificacion son Clasificacion lineal, regresion logistica, SVM que luego se detallaran en base a un problema concreto
    \section{Clasificacion mediante Aprendizaje Supervisado}
      \subsubsection{Introduccion}
	A continuacion abordaremos un problema, el cual servira de motivacion para luego explicar el uso de las redes neuronales convolucionales

      \subsubsection{Clasificacion de imagenes}
	Es un problema de asginar a una imagen de entrada una etiqueta de categoria a partir de un conjunto prefijado de categorias.
	Es uno de los principales problemas del area de vision por computadoras, que a pesar de su simplicidad tiene una gran cantidad y variedad de aplicaciones practicas, 
	al punto de que otros problemas provenientes del area de vision por computadores pueden ser como detección de objetos o segmentacion pueden ser reducidos a clasificacion de imagenes.

	\paragraph {Desafios}
	  Debido a que la tarea de reconocer un concepto visual es relativamente trivial para que lo realice una persona, vale la pena considerar los desafios involucrados desde la perspectiva de
	  un algoritmo de Vision por computadoras, teniendo en cuenta que la representacion pura de una imagen es un arreglo de 3 dimensiones que contiene valores de brillo. A continuacion de mencionan
	  algunos de los principales desafios
	  \begin{itemize}
	    \item Variacion del punto de vista: Una simple instancia de un objeto puede estar orientada de muchas formas frente a la camara que toma la imagen.
	    \item Variacion de escala: Las clases visuales suelen exhibir variaciones en su tamaño en el mundo real y no solo en lo referido a la imagen.
	    \item Deformacion: Muchos objetos de interes no tienen un cuerpo rigido y pueden ser deformados de muchas formas
	    \item Oclusion: Los objetos de interes pueden estar ocluidos y solo una pequeña porcion del objeto puede ser visible.
	    \item Condiciones de iluminacion: Los efectos de la iluminacion pueden influir de forma drastica a nivel de pixeles.
	    \item Influencia del fondo: los objetos de interes pueden estar inmersos en un ambiente en el cual sean dificiles de identificar.
	    \item Variaciones intra clase: Existen muchos instancias completamente distinta de una misma categoria de objetos.
	  \end{itemize}
	  Un buen modelo de clasificacion de imagenes debe ser tolerante a todos estos desafios presentados.

	\paragraph {Ciclo de Clasificacion de Imágenes}
	  \begin{itemize}
	    \item Conjunto de datos de entrada: El conjunto de datos de entrada es un conjunto de N imágenes, cada una etiquetada con una de las K diferentes categorias.  
	    \item Aprendizaje: En base al conjunto de datos de entrenamiento, el sistema debe aprender como identificar las caracteristicas de cada categoria para asi establecer un modelo clasificador.
	    \item Evaluación: Finalmente se evalua la calidad del modelo clasificador haciendo que prediga las etiquetas para un conjunto (de prueba) nuevo de imagenes que no habia visto antes, comparando las 
	    etiquetas correctas con las etiquetas predecidas por el clasificador se puede establecer una metrica de calidad, intuitivamente se espera que las etiquetas predecidas coincidan en la mayoria
	    de los casos con las etiquetas correctas.
	  \end{itemize}
      
      \subsubsection{Clasificación Lineal}
	Este enfoque tiene 2 componentes principales que luego seran extendidos a las Redes Neuronales: Una funcion de puntuación que asigna un puntaje de pertenencia de cada instancia a cada categoria, 
	y una función de pérdida que cuantifica la coincidencia entre los puntajes predecidos con los puntajes correctos.
	Este problema se reduce a un problema de optimización donde se requiere minimizar la función de pérdida con respecto a la función de puntuación.

    \subsection{Función de Puntuación}
      El primer componente desde este enfoque es definir una función de pérdida que mapee el valor de los pixeles de una imagen a un puntaje de confianza para cada categoría.
      Asumiendo que la entrada de la funcion son imagenes, cada una con una etiqueta de categoria dentro de las K categorias, la salida debe ser un valor de confianza de esa imagen 
      para cada una de las K categorias.
    Por ejemplo si tenemos 100 imagenes de 3 canales, de 32*32 pixeles y 10 categorias, definimos una funcion de puntuacion que toma entradas..

      \paragraph{Funcion Lineal:} 
	f(xi,W,b)=Wxi+b
	xi es una imagen representada por sus pixeles, W es un vector de pesos y b es un termino de regularizacion

    \subsection{Función de Pérdida}
      En la funcion lineal se puede observar que esta parametrizada por un conjunto de pesos.
      No se tiene control sobre los valores de los pixeles pero si se puede controlar el vector de pesos, de forma tal que el valor predecido sea consistente con el valor correcto. 
      La funcion de perdida pretende medir el error entre el valor predecido y el valor correcto, intutivamente la perdida sera mayor si el clasificador predice de forma erronea y 
      menor si lo hace de forma correcta.
      La idea es minimizar la funcion de perdida adaptando los valores de los pesos.

    \subsection{Optimización}
      El objetivo de la optimización es encontrar el vector de pesos W que minimice la funcion de perdida.

    \subsection{Gradiente} 
      La estrategia de optimización mas utilizada para este tipo de problemas es la de seguir la dirección del gradiente (también llamado derivadas) de la función de pérdida.
      En este caso que la función toma como entrada un vector de números, se aplican las derivadas parciales y el gradiente es el vector resultante de calcular las derivadas parciales
      en cada dimensión.

      \paragraph{Descenso por el gradiente}
	La idea de principal de este metodo es el refinamiento iterativo, se evalua el resultado del calculo del gradiente y se actualizan los parámetros repetidamente, 
	toma un hiperparametro llamado tasa de aprendizaje que define el tamaño de cada paso en la iteración.
	Este es el método mas utilizado para optimizar funciones de pérdida en las Redes Neuronales. 

      \paragraph{Descenso por el gradiente en lotes:} 
	En aplicaciones de gran escala, el conjunto de entrenamiento puede ser del orden de los millones de ejemplos, por lo que computar la funcion de 
	pérdida completa sobre todo el conjunto para actualizar un solo parámetro seria algo impracticable.
	Un enfoque común que se aplica a este problema es computar el gradiente sobre lotes del conjunto de entrenamiento, que permite lograr una buena aproximación al objetivo completo con
	una convergencia mucho mas rapida.

      \paragraph{Descenso por el gradiente estocástico:} 
	Es el caso extremo de la aproximación anterior donde el lote tiene solo un elemento.

      \paragraph{Otras formas de optimizacion}
	Existen otros metodos de optimizacion que trabajan de forma similar ADAM, LBFGS,RMSProp etc. DETALLAR.
	
    \subsection{Retropropagación}
      http://cs231n.github.io/optimization-2/
      Retropropagación (en inglés Backpropagation) una forma  de computar los gradientes de expresiones mediante la aplicacion recursiva de la regla de la cadena.
      El ciclo consta de 2 fases, propagación y luego actualizacion de parámetros. Cuando ingresan los parámetro a la función se calcula el resultado final, y se lo compara con el resultado 
      deseado, aplicando la función de pérdida se calcula el error, mediante el metodo de optimizacion se define el gradiente para luego realizar la retropropagación en la función hasta 
      actualizar los parametros.

    \section{Redes Neuronales Artificiales}
      Combinacion lineal de funciones no lineales
      An artificial neural network (ANN) learning algorithm, usually called "neural network" (NN), is a learning algorithm that is inspired by the structure and functional aspects 
      of biological neural networks. Computations are structured in terms of an interconnected group of artificial neurons, processing information using a connectionist approach 
      to computation. Modern neural networks are non-linear statistical data modeling tools. They are usually used to model complex relationships between inputs and outputs, 
      to find patterns in data, or to capture the statistical structure in an unknown joint probability distribution between observed variables.
      \paragraph {Ventajas}
	\begin{itemize}
	  \item Bueno para variables de entrada continuas
	  \item Aproximadores generales de funciones continuas
	  \item Altamente no lineales
	  \item Aprende funciones caracteristicas
	  \item Bueno para usar en dominios continuos con poco conocimiento:
	    \subitem Cuando no se conocen buenas caracteristicas
	    \subitem No se conoce la forma de un buen modelo funcional
	\end{itemize}
      \paragraph {Desventajas}
	\begin{itemize}
	  \item Los resultados intermedios no son interpretables, al resultado final se los considera como proveniente de una caja negra.
	  \item El aprendizaje es lento
	  \item Para lograr una buena generalizacion puede requerir muchos datos
	\end{itemize}

      \paragraph {Motivación biológica} 
	El area de las redes neuronales artificiales fue originalmente insipirada por el objetivo de modelar los sistemas neuronales biológicos, 
	pero luego fue divergiendo
	y convirtiendose en una tarea de Ingenieria para obtener buenos resultados dentro del area de Aprendizaje automatico.
	Dendritas, input axones, sinapsis y output.
	IMAGEN DE ANALOGIA

      \paragraph {Neurona artificialUnidad}
	Consta de un vector de entrada, un vector de pesos y una función de activación no lineal
	En una neurona se realiza el producto punto entre el vector de entrada, y su vector de pesos, le suma el sesgo y aplica la funcion de no linearidad.
	Una unica neurona puede ser utilizada para implementar un clasificador binario.

      \paragraph {Funciones de Activacion comunmente utilizadas}
	Toda funcion de activacion toma un unico numero como entrada, realiza un operacion matematica predefinida, no lineal y devuelve el resultado obtenido.
	Algunos ejemplos de funciones que se utilizan:
	\begin{itemize}
	  \item Sigmoid:
	  \item Tangente hiperbolica
	  \item ReLU:max(0,x)
	\end{itemize}

    \subsection {Arquitectura de las Redes Neuronales}
      Organización por capas: Las redes neuronales se pueden modelar como un conjunto de neuronas conectadas en un grafo aciclico, que se suelen organizar por capas, las neuronas de una capa
      se conectan con neuronas de sus capas adjacentes pero nunca se conectan 2 neuronas de una misma capa.
      Toda red neuronal tiene una capa de entrada, una capa de salida y un numero determinado de capas ocultas, que pueden ser de distintos tipos.
      Una de las principales razones por la cual las redes neuronales estan organizadas en capas, es que este tipo de estructura permite evaluar una red, muy simple y eficientemente realizando
      operaciones matriciales vectoriales, una red neuronal puede ser pensada como una serie de multiplicaciones de matrices entrelazadas con funciones de activaciones no lineales.
      Las redes neuronales utilizadas en la actualidad tienen alrededor de 100 millones de parametros distribuidos entre 10-20 capas.
      Al definir la arquitectura de la red, se forma lo que seria una funcion de puntuacion, una red neuronal realiza una combinacion lineal de funciones no lineales. 

    \subsection {Preprocesamiento de datos}
	Restarle la media a cada caracteristica
	Normalizacion
	PCA

    \paragraph {Inicializacion de los pesos}
      Error comun: Iniciar en 0.
      Inicializar con valores aleatorios cercanos a 0 

    \paragraph {Regularizacion: Dropout}


    \subsection {Entrenamiento}
      Consiste de 2 pasos: Paso hacia adelante, y paso de retroalimentacion
      \begin{enumerate}
      \item En el paso hacia adelante se evalua la red y se obtiene el resultado de salida, el cual se mide el error, se calcula el gradiente para luego aplicar el paso de retroalimentacion
	\item En el paso de retroalimentacion se ajustan los pesos internos de la red en base al resultado del gradiente.
      \end{enumerate}
      Esto se realiza iterativamente una cantidad predefinida de veces.

  \section {Deep Learning}
    La caída de los precios de hardware y el desarrollo de GPUs para uso personal en los últimos años han contribuido al desarrollo del concepto de aprendizaje profundo que consiste
    de múltiples capas ocultas en una red neuronal artificial. Este enfoque trata de modelar la forma en que el cerebro humano procesa luz y sonido en visión y audición.
    Algunas aplicaciones exitosas del aprendizaje profundo son la visión por computadora y el reconocimiento del habla.

  \section {Redes Neuronales Convolucionales}
    Las redes neuronales convolucionales son muy similares a las redes neuronales antes vista, con la diferencia en que la arquitectura de una red neuronal convolucional asume explicitamente
    que el conjunto de entrada son imagenes, lo que le permite codificar ciertas propiedades dentro de la arquitectura. 
    Estan inspiradas en las redes neuronales tradicionales, incorporando operaciones no-lineales de manipulación de imágenes.

    \subsection {Arquitectura de una red neuronal convolucional}
      Las redes neuronales convolucionales, las neuronas dentro de una capa se organizan en 3 dimensiones: alto, ancho y profundidad.
      Cada capa acepta un volumen de 3 dimensiones como entrada y lo transforma en un volumen de salida de 3 dimensiones a traves de una funcion diferenciable.
      Algunas capas pueden tener o no parametros, al igual que hiperparametros.

      En el caso mas simple de arquitectura, la red transforma el volumen de una imagen de entrada en un volumen de salida (conteniendo los puntajes de cada clase para el problema de clasificacion)

    \subsection {Tipos de Capas}
      \subsubsection{Capa Convolucional} 
	Los parametros consisten en un conjunto de filtros aprendibles. Cada filtro el pequeño espacialmente(alto y ancho) pero se extiende sobre toda la profundidad del volumen de entrada.
	Durante el paso hacia adelante, se desliza o convoluciona el filtro atraves del alto y ancho del volumen de entrada y se computa el producto punto entre los valores del filtro y los valores
	del volumen de entrada. A medida que se va deslizando el filtro sobre el ancho y el alto del volumen de entrada, se va generando un mapa de activacion de 2 dimensiones que contiene los 
	valores de respuesta de ese filtro en cada posicion espacial.
	Intuitivamente, la red aprenderá los filtros que se activan cuando ven algún tipo de característica visual como un borde de cierta orientación o una mancha de algún color en la 
	primera capa, o eventualmente panal entero o patrones de rueda en las capas más altas de la red. Dado que tendremos un conjunto de filtros en cada capa Convolucional, 
	y cada uno de ellos producirá un mapa de activación bidimensional separado, estos se apilaran a lo largo de la dimensión de profundidad para producir el volumen de salida.

	Backpropagation. The backward pass for a convolution operation (for both the data and the weights) is also a convolution (but with spatially-flipped filters)

      \subsubsection{Capa de Agrupamiento} 
	Su función es reducir progresivamente el tamaño espacial de la representación para reducir la cantidad de parámetros y de cálculo en la red, y por lo tanto también para controlar
	el Overfitting. La capa de agrupamiento funciona independientemente en cada segmento de profundidad de la entrada y la redimensiona espacialmente, utilizando la operación de máximo, 
	tambien se suele utilizar la operacion de promedio o la norma L2.

	Retroalimentacion
	el paso hacia atrás para una operación maximo tiene una interpretación sencilla, ya que sólo encamina el gradiente a la entrada que tenía el valor más alto en el paso hacia
	adelante. Por lo tanto, durante el paso hacia adelante de una capa de agrupamiento es común realizar un seguimiento del índice de la activación máxima de manera que 
	el enrutamiento de gradiente es eficiente durante la retropropagación.

      \subsubsection{Capa Completamente Conectada} 
	Las neuronas entre dos capas adyacentes están completamente conectadas de a pares, pero las neuronas dentro de una sola capa no comparten conexiones.

    \subsection {Consideraciones computacionales}
      El cuello de botella más grande a tener en cuenta al construir arquitecturas ConvNet es el cuello de botella de memoria. 
      Muchas GPUs modernas tienen un límite de memoria de 3/4 / 6GB, con las mejores GPUs que tienen cerca de 12GB de memoria. 
      Hay tres fuentes principales de memoria para realizar un seguimiento:
      \begin{itemize}
	\item A partir de los tamaños de volumen intermedios: Éstos son el número crudo de activaciones en cada capa de la ConvNet, y también sus gradientes (de igual tamaño). Normalmente, la mayoría de las activaciones se encuentran en las capas anteriores de una ConvNet (es decir, primeras capas de convección). Estos se mantienen alrededor porque son necesarios para backpropagation, pero una implementación inteligente que ejecuta un ConvNet sólo en tiempo de prueba podría en principio reducir esto en una cantidad enorme, sólo almacenando las activaciones actuales en cualquier capa y descartando las activaciones anteriores en las capas de abajo .
	\item A partir de los tamaños de parámetro: Estos son los números que contienen los parámetros de red, sus gradientes durante la retropropagación y, comúnmente, también un caché de pasos si la optimización utiliza impulso, Adagrad o RMSProp. Por lo tanto, la memoria para almacenar el vector de parámetros solo debe ser multiplicada por un factor de al menos 3 o más.
	\item Cada implementación de ConvNet tiene que mantener la memoria miscelánea, como los lotes de datos de imagen, tal vez sus versiones aumentadas, etc.
	Una vez que tenga una estimación aproximada del número total de valores (para activaciones, gradientes y misc), el número debe convertirse a tamaño en GB. Tome el número de valores, multiplique por 4 para obtener el número bruto de bytes (ya que cada punto flotante es 4 bytes, o tal vez por 8 para doble precisión), y luego dividir por 1024 varias veces para obtener la cantidad de memoria en KB, MB, y finalmente GB. Si su red no encaja, una heurística común para "hacerla encajar" es disminuir el tamaño del lote, ya que la mayor parte de la memoria suele ser consumida por las activaciones.
      \end{itemize}


    \subsection {Casos de estudio de redes convolucionales famosas}
      \begin{itemize}
	\item AlexNet
	\item VGG
	\item Inception
	\item Resnet
      \end{itemize}

    \section {Reentrenamiento}
    STANFORD
      El reentranmiento (Finetuning en inglés) toma un modelo ya entrenado, adapta la arquitectura y retoma el entrenamiento partiendo desde los pesos del modelo ya entrenado.
      \paragraph{Modelos preentrenados}
	Debido a que una red neuronal convolucional moderna requiere entre 2 y 3 semanas para entrenarse, utilizando multiples GPUs para el conjunto de datos ImageNet, es comun ver que gente
	publica sus Redes ya entrenadas para el beneficio de otras personas que lo pueden usar para hacer finetuning.
      \paragraph{Como y cuando hacer Reentrenamiento}
	¿Cómo decidir qué tipo de transferencia de aprendizaje debe realizar en un nuevo conjunto de datos? Esta es una función de varios factores, pero los dos más importantes son el 
	tamaño del nuevo conjunto de datos (pequeño o grande), y su similitud con el conjunto de datos original (por ejemplo ImageNet-como en términos de contenido de imágenes y las clases,
	O muy diferentes, tales como imágenes de microscopio). Teniendo en cuenta que las características de CNN son más genéricas en capas tempranas y más específicas del conjunto de datos
	originales en capas posteriores, aquí hay algunas reglas comunes para navegar por los 4 escenarios principales:
	\begin{itemize}
	  \item El nuevo conjunto de datos es pequeño y similar al conjunto de datos original. Dado que los datos son pequeños, no es una buena idea afinar la red convolucional debido a las 
	  preocupaciones excesivas. Dado que los datos son similares a los datos originales, esperamos que las características de mayor nivel en la red convolucional sean relevantes para este
	  conjunto de datos. Por lo tanto, la mejor idea podría ser la de formar un clasificador lineal utilizando las caracteristicas extraidas en la ultima capa de la red.
	  \item El nuevo conjunto de datos es grande y similar al conjunto de datos original. Dado que tenemos más datos, podemos tener más confianza de que no superaremos si intentáramos 
	  ajustar a través de la red completa.
	  \item El nuevo conjunto de datos es pequeño pero muy diferente del conjunto de datos original. Dado que los datos son pequeños, lo más probable es que sólo entrenen un clasificador 
	  lineal. Dado que el conjunto de datos es muy diferente, puede que no sea mejor entrenar al clasificador en la parte superior de la red, que contiene más características específicas
	  de conjunto de datos. En su lugar, podría funcionar mejor para entrenar el clasificador SVM de las activaciones en algún lugar anterior en la red.
	  \item El nuevo conjunto de datos es grande y muy diferente del conjunto de datos original. Dado que el conjunto de datos es muy grande, podemos esperar que podamos permitirnos 
	  entrenar a una red convolucional desde cero. Sin embargo, en la práctica es muy a menudo todavía beneficioso para inicializar con pesos de un modelo pre-entrenado. 
	  En este caso, tendríamos suficientes datos y confianza para afinar a través de toda la red.
	\end{itemize}
     \section {Otros conceptos relevantes}
	\subsubsection{Matriz de Gramm}
     
     
\chapter{Trabajo propuesto}
  \section{Algoritmo de Transferencia de estilo}
    \subsection{Introduccion}
    Ver Introduccion 
    \subsection{Sintesis}
      Cuando las Redes Neuronales Convolucionales (CNN) son entrenadas para reconocimiento de objetos, desarrollan una representacion de la imagen que hace que la información 
      del objeto sea cada vez más explícita a lo largo de la jerarquia de las capas de la red.Por lo tanto, a lo largo de la jerarquía de procesamiento de la red, 
      la imagen de entrada se transforma en representaciones que cada vez más se preocupan por el contenido real de la imagen en lugar del valor de sus píxeles detallados. 
      Podemos visualizar directamente la información que cada capa contiene sobre la imagen de entrada, reconstruyendo la imagen solo a partir de los mapas de caracteristicas
      de esa capa. Las capas más altas de la red capturan el contenido de alto nivel en términos de objetos y su ordenamiento en la imagen pero no se limitan a los valores de cada 
      pixel. En  cambio, las reconstrucciones de las capas inferiores simplemente pretenden reproducir los valores exactos de píxeles de la imagen original y algunas formas
      basicas como lineas o curvas. Por lo tanto, tomaremos a los mapas de características en las capas superiores de la red como el contenido representado.
      Para obtener la representacion del estilo de la imagen de entrada, se usa un espacio de caracteristicas originalmente diseñado para capturar información de texturas.
      Este espacio de caracteristicas esta construido sobre las respuestas de los filtros de cada capa de la red. Consiste en la correlación entre diferentes respuestas de los filtros.
      Incluyendo las correlaciones de multiples capas, se obtiene una representacion que captura información de la textura pero no del ordenamiento global de la imagen.
      Al reconstruir las imagenes a partir de las representaciones obtenidas, se puede observar que producen una version texturizada de la imagen que captura su 
      apariencia general en terminos de colores y estructuras localizadas, a estas representaciones las llamaremos representaciones de estilo.
      El principal descubrimiento de este articulo es que la representacion del estilo y el contenido de una imagen pueden ser separables con una Red Neuronal Convolucional entrenada 
      para el reconocimiento de objetos. De esta forma, al manipularse independientemente se pueden generar una nueva imagen desde 2 imagenes de entradas distintas, simultaneamente se corresponda con la representacion
      del contenido de una imagen y la respresentacion del estilo de la otra.

    \subsection{Metodos}
      Los resultados exhibidos fueron obtenidos utilizando la red VGG-19, de disponibilidad publica.
      Generalmente, cada capa de la red define un banco de filtros no lineal cuya complejidad aumenta con la posición de la capa en la red.
      Para visualizar la información de la imagen codificada en diferentes capas de la jerarquía se realiza descenso gradiente en una imagen de ruido blanco 
      para encontrar otra imagen que coincida con las características de respuesta de la imagen original.
      Funcion Perdida del Contenido ...
      Sobre las respuestas de la CNN en cada capa de la red construimos una representación de estilo que calcula las correlaciones entre las diferentes respuestas de los filtros.
      Estas correlaciones de las caracteristicas estan dadas por la matriz de Gram ...
      Para generar una textura que coincida con el estilo de una imagen dada, utilizamos el descenso de gradiente de una imagen de ruido blanco para encontrar otra imagen que coincida 
      con la representación de estilo de la imagen original. Esto se hace minimizando la distancia media cuadrada entre las entradas de la matriz de Gram de la imagen 
      original y la matriz de Gram de la imagen a generar.
      Funcion de Perdida del Estilo ...
      Para generar las imágenes que mezclan el contenido de una fotografía con el estilo de una obra de arte conjuntamente minimizamos la distancia de una imagen de ruido blanco 
      de la representación de contenido de la fotografía en una capa de la red y la representación de estilo de la obra de arte en un número de capas de la CNN.
      Funcion de Perdida total ...
    
  \section{Algoritmo de Reconocimiento de estilo}
    \subsection{Introduccion}
      Las imagenes pintadas por humanos suelen tener un significado y el estilo visual de la misma tiene un papel significativo en cómo se ve, por lo que comprender
      el estilo es crucial para poder comprender el significado que la imagen intenta transmitir, sin embargo el estilo no ha recibido  mucha atención en el area de investigación de visión por computadoras. 
      Aunque es simple para los observadores humanos, el estilo visual es un concepto difícil de definir rigurosamente ya que involucra el contexto historico del arte en ese momento.
      Encontramos que las características aprendidas en una CNN funcionan muy bien para esta tarea. Esto es sorprendente por varias razones: Las caracteristicas aprendidas
      fueron entrenadas en categorias de clases de objetos (Imagenet), y muchos estilos parecieran ser principalmente definidos por las elecciones de colores, aunque
      las caracteristicas de las CNN, superan comodamente a las caracteristicas de los histogramas de colores. Esto lleva a unas de las conclusiones de este trabajo:
      Las caracteristicas de nivel medio para los conjuntos de datos de objetos son genericos para el reconocimiento de estilo, y las de nivel superior para las caracteristicas
      mas manuales.
      Se compararon los predictores obtenidos con observadores humanos y esencialmente se obtuvieron niveles de precision similares.
    \subsection{Algoritmo de Aprendizaje}
      El algoritmo aprende a clasificar las imágenes nuevas según su estilo, utilizando las etiquetas provistas en el conjunto de entrenamient.
      Debido a que los conjuntos de datos que tratamos son bastante grandes y algunas de las características son de grandes dimensiónes, consideramos sólo clasificadores lineales, 
      dependiendo de características sofisticadas para proporcionar robustez. Utilizamos una implementación de fuente abierta de Descenso de Gradiente Estocástico con adaptación
      del Subgradiente. El proceso de aprendizaje optimiza la función ...
    \subsection{Caracteristicas de las imagenes}
	Para clasificar estilos, debemos elegir características de imagen apropiadas. Nosotros hipotetizamos que el estilo de imagen puede estar relacionado con muchas características diferentes, 
	incluyendo estadísticas de bajo nivel, las opciones de color, la composición y el contenido. Por lo tanto, probamos características que incorporan estos diferentes elementos, incluyendo características de la 
	literatura de reconocimiento de objetos. Evaluamos el rendimiento de una sola función, así como la segunda etapa de fusión de múltiples características.
	Las principales caracteristicas evaluadas fueron:
	\begin{itemize}
	 \item Histogramas de colores
	 \item Descriptores GIST
	 \item Caracteristicas extraidas de una CNN
	\end{itemize}
	Se encontro que las caracteristicas extraidas de una CNN son las que mejor precisión proveen a la hora de reconocer estilos.

  \section{Finetuning para reconocimiento de estilos}
    Basado en los resultados propuestos en el articulo antes mencionado, se realizo un finetuning sobre la red AlexNet, por cuestiones de simplicidad, utilizando
    el conjunto de datos Wikipaintings, para los 10 estilos que mas datos provee.

    
  \section{Descripcion del problema}
    Basado en el algoritmo de transferencia de estilo se pueden obtener resultados muy interesantes, sin embargo es necesario definir una serie de hiperparametros,
    que necesita el algoritmo para poder ejecutarse. El criterio de elección de estos hiperparámetros termina siendo muy influyente en el resultado final. 
    Los principales hiperparametros a definir son:
    \begin{itemize}
      \item Numero de iteraciones que se ejecutará el optimizador.
      \item Modelo de Red Neuronal Convolucional preentrenada que se utilizará (existen una variedad de CNN presentadas anteriormente) junto con las capas que se utilizaran de la 
      respectiva red tanto para calcular el estilo como el contenido.
      \item Imagen desde la cual comenzar la optimización, es posible comenzar desde una imagen de ruido, desde la imagen de contenido.
      \item Método de optimización a utilizar.
    \end{itemize}

    Para poder realizar una comparación entre los distintos resultados generados por el algoritmo, es necesario establecer una métrica.
  \section{Solucion propuesta}
    En la solución propuesta en este trabajo se plantea poder definir automáticamente el numero de iteraciones que debe ejecutarse el algoritmo hasta lograr obtener un resultado.
    El resto de los hiperparámetros permanecen predefinidos a mano, excepto la imagen de la cual comenzar que influye notablemente en la cantidad de iteraciones que debe realizar el 
    algoritmo para obtener un resultado aceptable.
    Existen una gran variedad de implementaciónes de código abierto que implementan este algoritmo. La que se decidió utilizar fue la de Justin Jhonson (\url{https://github.com/jcjohnson/neural-style}).
    Que es la opción de mayor aceptación en la industria.
    Para poder establecer una métrica de comparación, se realizó finetuning sobre AlexNet, con el conjunto de datos de Wikipaintings, para que la red reentrenada aprenda a reconocer
    el estilo de una obra de arte para los 10 estilos que mas datos provee, obteniendo una precision del 92%.
    De esta forma se van realizando evaluaciones del resultado obtenido por el algoritmo generador contra la predicción que realiza el modelo reentrenado para el reconocimiento de estilos.
    
  \printindex
\chapter{Experimentos}
\chapter{Conclusiones, Perspectivas y trabajos a futuro}
  \section{Conclusiones}
  \section{Trabajos a futuro}
\end{document}