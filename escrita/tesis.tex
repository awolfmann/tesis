\documentclass[a4paper,11pt,spanish]{book}
%\usepackage[utf8]{inputenc}
\usepackage[utf8x]{inputenc}
\usepackage{url}
\usepackage{makeidx}
\usepackage[procnames]{listings}
\usepackage{color}
\usepackage{graphicx} % graficos
\usepackage[spanish]{babel}

\newcommand*{\FIXME}[1]{{(\textbf{FIXME}) {#1}}}

\iffalse
\title{Transferencia de Estilo en Fotografias utilizando Redes Neuronales Convolucionales}   %note \\[1ex] is a line break in the title

\author{Wolfmann, Ariel Mauricio}             %your name
\college{Facultad de Matemática, Astronomía y Física\\[1ex]
		}  %your college
\university{Universidad Nacional de Córdoba}

%\renewcommand{\submittedtext}{change the default text here if needed}
%\degree{Licenciada en Ciencias de la Computación}     %the degree
\directors{Sanchez, Jorge}
\fi

\makeindex



\begin{document}
\definecolor{keywords}{RGB}{255,0,90}
\definecolor{comments}{RGB}{0,0,113}
\definecolor{red}{RGB}{160,0,0}
\definecolor{green}{RGB}{0,150,0}

\lstset{language=Python, 
        basicstyle=\ttfamily\small, 
        keywordstyle=\color{keywords},
        commentstyle=\color{comments},
        stringstyle=\color{red},
        showstringspaces=false,
        identifierstyle=\color{green},
        procnamekeys={def,class}}


\begin{titlepage}
  \begin{center}
  \vspace*{1in}
    \begin{Huge}
    \textbf{Trabajo Final}\\
    \textbf{Transferencia de Estilo en Fotografias utilizando Redes Neuronales Convolucionales} \\
    \end{Huge}
  \end{center}
  \begin{center}
    \begin{large}
      \vspace*{1in}
      Autor: Wolfmann, Ariel Mauricio\\
      Director: Sanchez, Jorge\\
    \end{large}
    \vspace*{0.15in}
     Marzo de 2017\\
    \vspace*{0.15in}
    Universidad Nacional de Córdoba\\
    \vspace*{0.15in}
    Facultad de Matemática, Astronomía y Física\\
    \vspace*{0.6in}
  \end{center}
\end{titlepage}

\pagebreak

\iffalse
\maketitle                  % create a title page from the preamble info
\include{abstract}          % include the abstract
\include{dedication}        % include a dedication.tex file
\include{acknowlegements}   % include an acknowledgements.tex file

\begin{romanpages}          % start roman page numbering
\tableofcontents            % generate and include a table of contents
\listoffigures              % generate and include a list of figures
\end{romanpages}            % end roman page numbering
\fi

\tableofcontents 

\chapter{Introducción}
  \paragraph{Contexto}
    En los ultimos años las fotografias estan cada vez mas pasando a ser un objeto virtual en lugar de fisico, de la mano del gran aumento en el uso de los dispositivos moviles 
    cualquier persona puede tomar miles fotografias en un instante de tiempo, y compartirla en las redes sociales.
    A partir de esto, se han desarrollado muchas aplicaciones entorno a las fotografias, ya sea desde redes sociales masivamente utilizadas, hasta aplicaciones que aplican efectos o filtros 
    a la fotografia para transformarla en un retrato en blanco y negro o sepia por ejemplo. \\
    Muy recientemente se han comenzado a desarrollar aplicaciones que logran transferir el estilo de una obra de arte a una fotografia. Esto es posible gracias al incremento 
    del poder de cómputo y al descenso del precio de los nuevos dispositivos, ya que las técnicas computacionales empleadas para esto, requieren un cómputo mucho mas complejo.\\
    Esta tarea requiere de la interacción de 2 de las principales areas de las Ciencias de la Computación y de gran auge en la actualidad: Visión por Computadoras y Aprendizaje Automático,
    que hasta hace un tiempo, iban evolucionando completamente en paralelo, independientemente una de la otra. Hoy en día se han logrado resultados completamente disruptivos, al aplicar
    Aprendizaje Automático para algunas de las principales tareas de Visión por Computadoras, como lo son la clasificacion de imagenes, detección y reconocimiento de objetos.\\
    El area de Vision por Computadoras es el área de las Ciencias de la Computación que se encarga de cómo las computadoras pueden lograr obtener una comprensión de alto nivel de imágenes digitales o videos. 
    Desde la perspectiva de la ingeniería, busca automatizar tareas que el sistema visual humano puede hacer. Incluye métodos para adquirir, procesar, analizar y comprender las imágenes del mundo real 
    con el fin de producir información numérica o simbólica para que puedan ser tratados por una computadora.\\
    El area de Aprendizaje Automático es el área de las Ciencias de la Computación que da a las computadoras la capacidad de aprender sin ser explícitamente programadas, explora el estudio 
    y la construcción de algoritmos que pueden aprender y hacer predicciones sobre los datos. Tales algoritmos lo logran siguiendo las instrucciones estrictamente estáticas del programa 
    mediante la fabricación de predicciones o decisiones impulsadas por datos​ a través de la construcción de un modelo generado con las muestras de entrada. El aprendizaje automático 
    se emplea en una serie de tareas informáticas en las que el diseño y la programación de algoritmos explícitos son inviables, como por ejemplo para la detección de Spam, el reconocimiento
    óptico de caracteres y los motores de búsqueda.\\
    Dentro del Aprendizaje Automático, existe un subdominio llamado Aprendizaje Profundo, basado en un conjunto de algoritmos que intentan modelar abstracciones de alto nivel en los datos,
    mediante Redes Neuronales Artificiales de gran profundidad.\\
    La principal herramienta elegida para poder llevar a cabo la transferencia de estilo en fotografias son las Redes Neuronales Convolucionales, estas Redes Neuronales Artificiales asumen 
    explicitamente que los elementos de  entrada del algoritmo serán imágenes, lo cual le permite implementar ciertas optimizaciónes dentro del algoritmo, luego
    se irán explicando mas detalladamente todos estos conceptos en profundidad.\\
    Otro ejemplo de amplia investigación y desarrollo en la actualidad son los autos que se conducen por si solos, los cuales emplean estas técnicas dentro de sus procesos para lograrlo.
  \FIXME{TESIS SOBRE IMÁGENES $\Rightarrow$ PONER MUCHAS IMÁGENES. SIRVE PARA MOTIVAR Y FIJAR IDEAS AL MISMO TIEMPO QUE INCENTIVÁS AL LECTOR A SEGUIR LEYENDO}
  
  \paragraph{Motivación}
    En lo que respecta al área de visión por computadoras, una imagen es representada por un arreglo de 2 dimensiones donde cada valor representa la intensidad captada por un sensor 
    de un determinado punto espacial, representados como píxeles. La representación de los píxeles es muy sensible a cambios en la iluminación, ángulo, contraste y tamaño que pueda existir.\\
    Además, este tipo de representación es insuficiente para proveerla como dato de entrada de un algoritmo que se encargue de realizar alguna de las tareas antes mencionadas, como la
    detección de objetos o la transferencia de estilos, ya que para estos, es necesario proveer una representación de mas alto nivel, que permita detectar caracteristicas de alto nivel,
    como formas, contornos, etc. Debido a esto se suelen utilizar representaciones intermedias para este tipo de algoritmos, para el caso del problema de transferencia de estilo, 
    al utilizar Redes Neuronales Convolucionales, estas redes aprenden a generar representaciones intermedias de alto nivel, es decir, conceptos dados a nivel semántico.\\
    Existen articulos de investigación en los cuales se definen algoritmos para la transferencia de estilos artisticos en fotografias, que se basan en modelos estocasticos, 
    los cuales requieren una gran cantidad de hiperparámetros predefinidos empiricamente, es decir parámetros que deben ser fijados previo a la ejecución del algoritmo que dependen 
    de la elección propia del usuario, pero que influyen en gran manera sobre el resultado. Al ser modelos estocásticos, se basan en la idea de iterativamente, 
    minimizar una funcion de perdida hasta lograr el objetivo deseado. \\
    El principal objetivo de este trabajo es poder realizar una elección inteligente de uno de los principales hiperparámetros como lo es el número de iteraciones 
    que debe realizar el algoritmo hasta obtener un resultado interesante. \\
    Para poder determinar cuando un resultado logra ser aceptable es necesario definir una métrica para esto.
    Debido a que las obras de arte, sueles calificadas con metricas cualitativas y no tanto cuantitativas, se decidió utilizar otra red neuronal convolucional, 
    entrenada especialmente para reconocer estilos artisticos y en base a los resultados que arroja se define si el numero de iteraciones es suficiente para generar el resultado final 
    o es necesario continuar iterando.
  
  \paragraph{Estructura del trabajo}
    A lo largo de este trabajo se hará un recorrido por los principales conceptos para comprender tanto el problema como la solución y las técnicas empleadas.\\
    El capítulo 2 se desarrolla el marco teórico y cuestiones formales requeridas, principalmente orientado al aprendizaje Automatico y a las redes neuronales.\\
    En el capitulo 3 se hara un recorrido por los principales articulos de investigación y los algoritmos alli definidos para las tecnicas de transferencia estilos artisticos en fotografias.
    Para luego, en el capítulo 4 abordar en detalle la solución propuesta, junto con un análisis y evaluación empírica de la misma.\\
    En el capítulo 5 contiene los experimentos realizados y los resultados obtenidos, para finalmente en el capitulo 6 establecer una conclusión acerca del trabajo realizado, 
    junto con las perspectivas y posibles tareas a futuro.\\

Para introducir al lector en el tema, a continuación se muestran algunos ejemplos de resultados generados transfiriendo el estilo artistico a fotografias:
\FIXME{TESIS SOBRE IMÁGENES $\Rightarrow$ PONER MUCHAS IMÁGENES. SIRVE PARA MOTIVAR Y FIJAR IDEAS AL MISMO TIEMPO QUE INCENTIVÁS AL LECTOR A SEGUIR LEYENDO, ADJUNTAR EJEMPLOS}



\chapter{Marco Teórico}

%Material para revisar
%http://cs231n.github.io/
%Capítulo 2 del Mitchel (1997), Capítulos 3 y 6 del Mitchel (1997)
%Wolpert, D.H., Macready, W.G. (1997), "No Free Lunch Theorems for Optimization," IEEE Transactions on Evolutionary Computation 1, 67
%http://en.wikipedia.org/wiki/Inductive_bias
%http://en.wikipedia.org/wiki/Overfitting
%http://en.wikipedia.org/wiki/SURF
%Capítulo 5 del Marlsand (2009) "Machine Learning, an Algorithmic Perspective"
%Capítulo 5 del Smola & Vishwanathan (2008) "Introduction to Machine Learning"
%http://en.wikipedia.org/wiki/Logistic_regression
%http://en.wikipedia.org/wiki/Linear_regression
%Capítulo 13 del Owen et al. (2012), Capítulo 2 y 4 del Owen et al. (2012)
%http://ufal.mff.cuni.cz/~zabokrtsky/courses/npfl104/html/feature_engineering.pdf
%http://aprendizajengrande.net/cronograma.html
%http://www.deeplearningbook.org/
%Bishop



  \section{Aprendizaje Automatico}
%https://en.wikipedia.org/wiki/Machine_learning
    \subsection{Introducción}
      El Aprendizaje Automático (o machine learning, por su denominación en inglés) es un subcampo de las ciencias de la computacion que le otorga a las computadoras la habilidad de aprender o inferir reglas que no fueron explicitamente programadas.
      Surge desde el estudio de reconocimiento de patrones, y el aprendizaje computacional, provenientes de la Inteligencia aritificial, este campo explora el estudio y la construccion de algoritmos
      que pueden aprender y realizar predicciones a partir de datos. En base a las reglas determinadas explicitamente en el programa y los datos de ejemplo, se crea un modelo que intenta predecir
      características de un dato nuevo. Este tipo de algoritmos tienen su enfoque basado en los datos.\\
      Tom M. Mitchell elaboró una definición más formal de este concepto de aprendizaje: “se dice que un programa de computadora aprende de una experiencia E con respecto a una clase 
      de tarea T y medición de desempeño P, si su desempeño en la tarea T, medido por P, mejora con la experiencia E” [Mitchell,1997].\\
      El aprendizaje automático es esencialmente una forma de estadística aplicada con énfasis en el uso de computadoras para estimar estadísticamente funciones complicadas.
      \FIXME{AGREGAR EJEMPLO, DETECCION DE NUMEROS EN IMAGENES O ALGUN OTRO?}
      
    \subsection{Datos}
      Al ser un área que tiene su enfoque basado en los datos de entrada, estos pasan a cumplir un rol fundamental en el desarrollo del algoritmo, por ello es necesario que 
      estén los mas limpios y puros posible, es decir lograr obtener un conjunto de datos útiles a los que se le puedan aplicar algoritmos de aprendizaje automático, 
      motivo por el cual en muchas ocasiones se realiza una fase de preprocesamiento de datos, la cual puede llegar a ser la etapa que mas trabajo requiera del proceso completo. 

    \subsection{Modelos}

      \paragraph{¿Qué es un modelo?}
      “Un ente que aprende que no asume nada acerca de la identidad del concepto objetivo no tiene ninguna base racional para clasificar cosas que nunca vio.”
      Mitchel (1997)
      El principal objetivo de un sistema de aprendizaje es generalizar desde su experiencia o conocimiento previo. Generalizar en este contexto es la habilidad del sistema de realizar
      predicciones con precision sobre un ejemplo nuevo no visto antes, luego de aprender sobre el conjunto de entrenamiento. Los ejemplos de entrenamiento provienen de un espacio 
      con probabilidad de distribución desconocida del cual es considerado representativo. El sistema de aprendizaje debe construir un modelo sobre el espacio total que le permite realizar
      predicciones lo suficientemente precisas sobre nuevos ejemplos.
      \begin{itemize}
	\item Los modelos capturan la información en los datos de entrada (o en los datos en general, en aprendizaje no supervisado)
	\item Representan la forma de ver el mundo que permite extrapolar cuando se observan nuevos datos (nunca vistos).
	\item Los modelos pueden ser matemáticamente bien formados (estadísticos) o simplemente algoritmicos (cascadas de if-then-else).
	\item El modelo como código objeto: Diferenciamos el modelo del algoritmo usado para obtener el modelo.
      \end{itemize}


    \subsection{Características para el Aprendizaje}
      \FIXME{REVISAR}
      \FIXME{REFERENCIAS Y EXPLICACIÓN BREVE. ESTO VALE PARA TODOS LOS EJEMPLOS/MODELOS QUE SE MENCIONAN}
      \FIXME{Posible Referencia \url{http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/}}
      Para que un modelo pueda aprender, es necesario definir las caracteristicas (features en inglés) que este deberá aprender a partir de las instancias de entrenamiento.
      Una Feature es una pieza de información que podría ser útil para la predicción. Cualquier atributo podría ser una caracteristicas, siempre y cuando sea útil para el modelo.
      La ingeniería de caracteristicas (feature engineering en la literatura en ingles) es considerado un tema informal dentro del aprendizaje automático, sin embargo es sumamente
      relevante a la hora de poner en practica los algoritmos de esta area.
      Segun el tipo de dato, las caracteristicas iran variando. \\
      Por ejemplo para representar un documento de texto, el metodo mas utilizado es la bolsa de palabras.
      Este metodo genera una caracteristica por cada palabra de su vocabulario, y cada documento es representado por un vector, cada posicion del vector se asocia a una palabra del 
      vocabulario y el valor que posee esa posición es la cantidad de veces que aparece la palabra asociada.

      \subsubsection{Representando imágenes}
	Es un campo de investigación que en la actualidad se encuentra muy activo. El método más sencillo es usar el valor de los píxeles directamente, aunque este no generaliza muy bien
	Pero puede mejorar utilizando transformaciones algorítmicas del conjunto de entrenamiento el siguiente paso seria tomar el promedio sobre pequeños cuadrados de la imágen.
	Necesitamos de alguna funcion compleja que comprenda el significado de la imágen más allá de la representación numérica de la misma.
	A lo largo del desarrollo de la visión por computadora se distinguen dos enfoques para la generacion de descriptores capaces de reconocer caracteristicas de una imagen: 
	El enfoque basado en técnicas superficiales (o “shallow” en inglés) y el enfoque de aprendizaje profundo (o “deep” en inglés).
	\subsubsection{Enfoque Superficial}
	  El enfoque superficial responde a la manera tradicional de hacer visión por computadoras. Se busca generar una representación invariante a la posición, iluminación, fondo,
	  etc. utilizando principalmente técnicas estadísticas a partir de conocimiento anterior del objeto y del contexto. Los descriptores superficiales son diseñados a mano a 
	  partir de características físicas, hipótesis y observaciones. El enfoque entonces no aprende features de los objetos sino que se procesa la imágen de interés con un 
	  extractor de features prefijadas y luego se pasa la nueva representación a un clasificador entrenable. Los métodos más utilizadas que generan este tipo de descriptores s
	  on SIFT, SURF y Vectores Fisher.
	\subsubsection{Enfoque de Aprendizaje Profundo} 
	  La filosofía de estas técnicas se basa en la hipótesis de “un único algoritmo de aprendizaje”: El cerebro usa esencialmente el mismo algoritmo para comprender diferentes formas de entrada. 
	  Es entonces que en este enfoque se contempla que la complejidad de la percepción no está en el algoritmo ni en las estructuras de aprendizaje, sino en los datos. 
	  El enfoque de aprendizaje profundo consiste de técnicas, algoritmos y estructuras inspiradas en el cerebro que son capaces de aprender features por sí mismas, 
	  en lugar de que sean diseñadas a mano y prefijadas en el detector. El problema asociado a esto es que no sabemos qué features el modelo aprende durante el entrenamiento.
	  Las estructuras de aprendizaje profundo de features contemplan el concepto heredado de la neurobiología de que las features son jerárquicas: 
	  desde features de bajo nivel como bordes y contornos, hasta estructuras y objetos. Las Redes Neuronales Convolucionales soportan el aprendizaje de este tipo features 
	  y es el modelo que analizaremos posteriormente en este trabajo.
	 \FIXME{SHALLOW VS DEEP / HAND-CRAFTED VS LEARNED. VER SLIDES DE ANDREA VEDALDI
            \url{http://www.robots.ox.ac.uk/~vedaldi//assets/teach/vedaldi14bmvc-tutorial.pdf}.
            AL PLANTEAR EL PROBLEMA DE ML EN CV HACERLO DE TAL FORMA DE QUE QUEDE CLARO QUE HAY UNA REPRESENTACIÓN INTERMEDIA DE LAS IMAGENES.}
       
      \subsection{Entrenamiento}
	\subsubsection{Función de Puntuación}
	
	\subsubsection{Función de Pérdida}
	  Una función de pérdida es una función real, no negativa L(ˆy , y), que mide cuán diferente es la predicción y ˆ obtenida por la hipótesis h θ , con respecto a la
	  salida esperada y. Existen diversas funciones de pérdida que se utilizan en distintos contextos. A continuación se presentan algunas que se aplican usualmente:
	  \paragraph{Función de Pérdida 0-1}
	  \paragraph{Función de Pérdida Hinge}
	  \paragraph{Función de Pérdida Logistica}
	  \paragraph{Función de Pérdida de Entropia Cruzada}

	\subsubsection {Seleccion del Modelo}
	
	\subsubsection {Fase de Aprendizaje}
	  \begin{itemize}
	    \item Antes de comenzar el entrenamiento el conjunto de datos se divide en 2 subconjuntos, un conjunto de datos de entrenamiento y un conjunto de datos de prueba. 
	    \item Para entrenar el modelo solo se utiliza el conjunto de datos de entrenamiento, el conjunto de datos de prueba se separa.
	    \item Determinar la estructura del modelo de aprendizaje, en base al tipo de problema y a la forma en la que se representan las caracteristicas de los datos.
	    \item En algunos modelos, a partir del conjunto de datos de entrenamiento, se realiza otra particion de un pequeño subconjunto llamado conjunto de datos de validacion, este conjunto sirve 
	    para afinar ciertos hiperparametros del modelo.
	    \item Entrenar el modelo elegido sobre el conjunto de datos de entrenamiento
	  \end{itemize}
	
	\subsubsection {El problema del Sobreajuste}
	  Uno de los principales objetivos de los algoritmos de aprendizaje automático es su capacidad de generalizar a ejemplos nunca antes vistos. Sin embargo, si la fase 
	  de aprendizaje se realiza durante demasiado tiempo o si los ejemplos del conjunto de entrenamiento son raros, el modelo aprendido podría ajustarse específicamente 
	  a ciertas características aleatorias de estos datos, que en realidad no contribuyen a la generalización. Esto se conoce como sobreajuste (overfitting en la literatura en inglés), 
	  y es un problema importante y ampliamente discutido en el campo de aprendizaje automático. En el proceso de sobre ajuste, el desempeño del algoritmo en el
	  conjunto de entrenamiento sigue mejorando, pero en el conjunto de evaluación empeora.
	  
	\subsubsection {Regularizacion}
	  Una técnica para evitar el sobre ajuste de modelos es utilizar regularización. Esencialmente, consiste en penalizar los parámetros del modelo para evitar su
	  crecimiento desmedido, agregando un regularizador a la Función de Perdida.
	  \FIXME{AGREGAR Ecuacion de REGULARIZACION}
	  
	\subsubsection {Cros-validación}
	  Dividir el conjunto de datos en un conjunto de entrenamiento fijo y un conjunto de prueba fijo puede ser problemático, lo que resulta en que el conjunto de prueba es pequeño. 
	  Un pequeño conjunto de pruebas implica incertidumbre estadística alrededor del error de prueba promedio estimado, lo que hace difícil afirmar que el algoritmo A funciona mejor que el algoritmo B en la tarea dada.
	  Este procedimiento se basa en la idea de repetir el cálculo del entrenamiento y la prueba en diferentes subgrupos seleccionados aleatoriamente o divididos del conjunto de datos original.
	  Es prácticamente como entrenar y testear en los mismo datos, suponiendo que los datos estan partidos en 3 subconjuntos: datos = {A,B,C}, el procedimiento seria el siguiente:
	  \begin{itemize}
	    \item entrenar en A,B, testear en C
	    \item entrenar en A,C, testear en B
	    \item entrenar en B,C, testear en A
	  \end{itemize}

      \subsection{Evaluación}
	Para poder determinar el grado confianza \FIXME{Revisar} de un modelo y ademas para poder compararlo con otros modelos, es necesario evaluarlo. 
	A la hora de evaluar un modelo se utilizan diferentes tipos de metricas, en esta seccion se iran algunas de las principales metricas utilizadas.    
	\subsubsection {Evaluando modelos}
	  \begin{itemize}
	    \item Medir cuantas veces un sistema devuelve la respuesta correcta (“exactitud/accuracy”) no es suficiente
	    \item Muchos problemas de interés práctico tienen un gran sesgo hacia una sola clase (clase de fondo)
	    \item Si el 95% de las veces algo no ocurre, decir que nunca ocurrirá (¡un modelo que no es particularmente muy útil!) se equivocará sólo un 5% del tiempo
	    \item Datos apartados (no entrenar y testear sobre los mismos datos)
	    \item Los datos apartados tienen que ser representativos del problema y la población donde se utilizará el sistema
	  \end{itemize}
	\subsubsection {Metricas}
	\subsubsection {Precisión, exhaustividad y exactitud}
	  Si se ejecuta un clasificador binario sobre un conjunto de evaluación, existen cuatro resultados posibles para cada elemento clasificado:
	  \begin{itemize}	
	    \item Verdadero Positivo: el elemento se clasificó como positivo, y su valor real es positivo.
	    \item Verdadero Negativo: el elemento se clasificó como negativo, y su valor real es negativo.
	    \item Falso Positivo: el elemento se clasificó como positivo, pero su valor real es negativo.
	    \item Falso Negativo: el elemento se clasificó como negativo, pero su valor real es positivo.
	  \end{itemize}
	  \FIXME{Agregar cuadro}
	  
	  Considerando los resultados del clasificador ejecutado sobre todo el conjunto de evaluación, se definen:
	  \begin{itemize}	
	    \item VP: cantidad de elementos que resultaron Verdaderos Positivos.
	    \item VN: cantidad de elementos que resultaron Verdaderos Negativos.
	    \item FP: cantidad de elementos que resultaron Falsos Positivos.
	    \item FN: cantidad de elementos que resultaron Falsos Negativos.
	  \end{itemize}	  
	  
	  Con estos valores se pueden definir las métricas que se detallan a continuación.
	  
	  \paragraph { Precisión }
	    La precisión del clasificador se define como el número de Verdaderos Positivos (es decir, la cantidad de elementos clasificados correctamente en la clase positiva)
	    dividido por el total de elementos clasificados en la clase positiva (esto es, la suma de los Verdaderos Positivos y los Falsos Positivos). Se puede expresar como:
	    \FIXME{Agregar Formula Precision}
	    Una precisión de 1.0 para un clasificador significa que todo elemento asignado a la clase positiva pertenece realmente a dicha clase, aunque no dice nada acerca
	    de los elementos de la clase positiva que fueron asignados incorrectamente a la clase negativa.
	  
	  \paragraph { Exhaustividad }  
	    La exhaustividad de un clasificador (recall en la literatura en inglés) se define como el número de Verdaderos Positivos dividido por el número total de elementos que 
	    realmente pertenecen a la clase positiva (es decir, la suma de los Verdaderos Positivos y los Falsos Negativos). Se puede expresar de la siguiente manera:
	    \FIXME{Agregar Formula Exhaustividad}
	    Un valor de 1.0 de exhaustividad indica que todos los elementos de la clase positiva fueron asignados a la clase positiva, aunque no dice nada acerca de cuántos elementos 
	    fueron además incorrectamente asignados en dicha clase.
	  
	  \paragraph { Métrica F }
	    Por lo general, las métricas de precisión y exhaustividad no se analizan por separado. Una forma de análisis es observar el valor de una, fijando un nivel en la otra 
	    (por ejemplo, la precisión con un nivel de exhaustividad de 0.90). Además, existen métricas que combinan ambos valores, como es la Métrica F:
	    \FIXME{Agregar Formula Métrica F}
	  
	  \paragraph { Exactitud }
	    La exactitud (accuracy en la literatura en inglés) se define como la proporción de resultados verdaderos (Verdaderos Positivos y Verdaderos Negativos) entre el total 
	    de elementos examinados (es decir, el tamaño del conjunto de evaluación). Expresado como una fórmula resulta:
	    \FIXME{Agregar Formula Exactitud}

	  \paragraph {ROC}
	    \begin{itemize}
	      \item Cuando se puede variar Precision/Recall con un parámetro, esto forma una curva
	      \item El área bajo esa curva nos dá la idea de que tan bien funciona un sistema
	      \item Un sistema que funciona todo el tiempo con muy buena precision y recall, tendrá un área muy grande
	      \item Un sistema que tiene gran precision pero clasifica pocas instancias y muy poca precision cuando clasifica muchas tendrá muy poca área
	      \item Promediado micro y macro
	      \item Cuando el sistema se ejecuta sobre varios conjuntos de testeo
	    \end{itemize}

    \subsection{Ciclo del Aprendizaje Automático}
      Luego de explicar todos los conceptos relevantes al Aprendizaje automático, podemos resumir al ciclo común a todos los algoritmos de Aprendizaje automático a lo siguiente: 
      \begin{itemize}
	\item Recopilación de datos:
	  El recopilado de datos es crucial, puede requerir mucho esfuerzo y cambio de procesos complejos, 
	  Anotación, Muchas veces la clase objetivo tiene que ser calculada a mano por grupos de personas designadas para la tarea.
	\item Preprocesamiento de datos: Una vez obtenidos los datos, es necesario preprocesarlos para lograr tener datos limpios y utiles. Esta fase puede contener una etapa 
	  de exploracion y analisis, la cual permite conocer el dominio de donde provienen los datos.  
	\item Definicion de caracteristicas: Para definir las caracteristicas que el modelo debe aprender, en muchas ocasiones es necesario tener conocimiento del dominio a partir del cual provienen los datos. 
	  La ingeniería de features ayuda a obtener caracteristicas que provean informacion relevante a la hora de predecir.
	\item Entrenamiento
	  \subitem Antes de comenzar el entrenamiento el conjunto de datos se divide en 2 subconjuntos, un conjunto de datos de entrenamiento y un conjunto de datos de prueba. 
	  \subitem Para entrenar el modelo solo se utiliza el conjunto de datos de entrenamiento, el conjunto de datos de prueba se separa.
	  \subitem Determinar la estructura del modelo de aprendizaje, en base al tipo de problema y a la forma en la que se representan las caracteristicas de los datos.
	  \subitem En algunos modelos, a partir del conjunto de datos de entrenamiento, se realiza otra particion de un pequeño subconjunto llamado conjunto de datos de validacion, este conjunto sirve 
	  para afinar ciertos hiperparametros del modelo.
	  \subitem Entrenar el modelo elegido sobre el conjunto de datos de entrenamiento
	\item Evaluacion
	  Se aplica el modelo entrenado a los datos del conjunto de prueba, y se aplican métricas para poder establecer que tan bien predice el modelo entrenado para datos nunca antes vistos.
      \end{itemize}
    

  \section{Clasificacion de algoritmos de aprendizaje automático}
    Dentro del aprendizaje automático, los algoritmos se pueden clasificar segun la forma en la que aprenden de sus datos, en algoritmos de aprendizaje supervisado, no supervisado, 
    semi-supervisado o por refuerzo.

    \subsection{Aprendizaje Supervisado}
      Los algoritmos de aprendizaje supervisado son, a groso modo, algoritmos de aprendizaje que aprenden a asociar alguna entrada con alguna salida, 
      dado un conjunto de entrenamiento de ejemplos de entradas x y salidas y.
      Consisten en aprender una función, a partir de datos de entrenamiento etiquetados. Cada ejemplo del conjunto de entrenamiento suele ser un par
      compuesto de un objeto de entrenamiento(representado por un vector de caracteristicas) y una etiqueta, que seria el valor de salida deseado.
      El problema tipico que se ataca con estos algoritmos es el de clasificación. \\
      Clasificacion se define como el problema de identificar a que categoria pertenece una nueva observacion,
      basada en el conjunto de datos de entrenamiento, que contiene observaciones a las cuales se les conoce si categoria.
      Otra opcion es la regresion que en lugar de determinar a que categoria pertenece, define un puntaje de pertenencia a cada categoria.
      El Aprendizaje Automático supervisado:
      \begin{itemize}
	\item Aprender lo que uno ya sabe
	\item Tratar de aprender una función f(x1, …, xn) → y donde
	\item xi son las caracterísita de aprendizaje (features) de entrada
	\item y es la clase objetivo
	\item La clave es extrapolación, queremos que la función generalize a entradas nunca vistas.
	\item Interpolación lineal es en sí una forma de hacer Aprendizaje Automático supervisado.
	\item Una visión como desarrolladores
	\item Entrenamiento/Estimación/“compilación”:
	\item Entrada: vectores de features, incluyendo la clase objetivo
	\item Salida: un modelo entrenado
	\item Ejecución/Predicción/“interpretado”:
	\item Entrada: vectores de features, sin la clase objetivo, más el modelo entrenado
	\item Salida: la clase objetivo predicha
      \end{itemize}
      
      \subsubsection{Clasificacion}

      Ejemplos de algoritmos de clasificacion son Clasificacion lineal, regresion logistica, SVM que luego se detallaran en base a un problema concreto.
  
    \subsection{Aprendizaje No Supervisado} 
      \begin{itemize}
	\item La caracteristica principal de este tipo de algoritmos es que los datos de entrenamiento no estan etiquetados
	\item El principal algoritmo de aprendizaje no supervisado es el de Agrupamiento (Clustering en la literatura en inglés).
      \end{itemize}
      \subsubsection {Agrupamiento}
	\begin{itemize}
	  \item Consiste en agrupar objetos, de forma tal que los objetos pertenecientes a un mismo grupo son en algun sentido mas similares entre ellos que a los objetos que pertenecen a otro grupo.
	  \item El objetivo de los métodos de clustering es descubrir grupos significativos presentes en los datos.
	  \item El concepto central en clustering es la definición de una función de distancia entre instancias
	  \item Cada definición de distancias induce un agrupamiento de los datos, basado en esa métrica
	  \item La distancia es donde se incorpora la información humana
	\end{itemize}

    \subsection{Aprendizaje Semi-Supervisado}

      Estos algoritmos se caracterizan por utilizar una pequeña cantidad de datos etiquetados y otro gran conjunto de datos no etiquetados
      Principal problema atacado:
      \subsubsection {Recomendación}
	\begin{itemize}
	  \item Un problema en el medio entre supervisado y no supervisado
	  \item Dado un conjunto de personas y objetos, recomendar nuevos objetos similares a los que la persona elige, pero que no conoce
	  \item Amplia utilidad práctica
	  \item Collaborative Filtering
	  \item Filtrar información usando comunidades de personas
	  \item Usuarios, ítems y preferencias
	\end{itemize}
      \paragraph {Recomendación basada en Usuarios}
	\begin{itemize}
	  \item para cada ítem i para el cual el usuario u no tiene preferencia:
	    \subitem para cada otro usuario v que tiene preferencia por i:
	      \subsubitem calcular la similitud s entre u y v
	      \subsubitem acumular la preferencia de v por i, pesada por s
	      \subsubitem devolver los ítems con mayor preferencia pesada
	\end{itemize}
      \paragraph {Recomendación basada en Items}
	\begin{itemize}
	  \item para cada ítem i para el cual el usuario u no tiene preferencia:
	    \subitem para cada ítem j que u tiene una preferencia:
	      \subsubitem calcular la similitud s entre i y j
	      \subsubitem acumular la preferencia de u por j, pesada por s
	      \subsubitem devolver los ítems con mayor preferencia pesada
	\end{itemize}
    
    \subsection{Aprendizaje por Refuerzo}
      El sistema interactua en un ambiente dinamico en el cual debe cumplir un objetivo determinado, el programa va recibiendo retroalimentacion en terminos de premios y castigos mientras 
      recorre el espacio del problema y de esta forma aprende.
      \FIXME{AGREGAR EJEMPLO}

    
    \section{Clasificacion mediante Aprendizaje Supervisado}
      \subsection{Introduccion}
	A continuacion abordaremos un problema, el cual servirá de motivación para luego explicar el uso de las redes neuronales convolucionales.

      \subsection{Clasificacion de imagenes}
	Es un problema de asginar a una imagen de entrada una etiqueta de categoria a partir de un conjunto prefijado de categorias.
	Es uno de los principales problemas del area de vision por computadoras, que a pesar de su simplicidad tiene una gran cantidad y variedad de aplicaciones practicas, 
	al punto de que otros problemas provenientes del area de vision por computadores pueden ser como detección de objetos o segmentacion pueden ser reducidos a clasificacion de imagenes.

	\subsubsection {Desafios}
	  Debido a que la tarea de reconocer un concepto visual es relativamente trivial para que lo realice una persona, vale la pena considerar los desafios involucrados desde la perspectiva de
	  un algoritmo de Vision por computadoras, teniendo en cuenta que la representacion pura de una imagen es un arreglo de 3 dimensiones que contiene valores de brillo. A continuacion de mencionan
	  algunos de los principales desafios
	  \begin{itemize}
	    \item Variacion del punto de vista: Una simple instancia de un objeto puede estar orientada de muchas formas frente a la camara que toma la imagen.
	    \item Variacion de escala: Las clases visuales suelen exhibir variaciones en su tamaño en el mundo real y no solo en lo referido a la imagen.
	    \item Deformacion: Muchos objetos de interes no tienen un cuerpo rigido y pueden ser deformados de muchas formas
	    \item Oclusion: Los objetos de interes pueden estar ocluidos y solo una pequeña porcion del objeto puede ser visible.
	    \item Condiciones de iluminacion: Los efectos de la iluminacion pueden influir de forma drastica a nivel de pixeles.
	    \item Influencia del fondo: los objetos de interes pueden estar inmersos en un ambiente en el cual sean dificiles de identificar.
	    \item Variaciones intra clase: Existen muchos instancias completamente distinta de una misma categoria de objetos.
	  \end{itemize}
	  Un buen modelo de clasificacion de imagenes debe ser tolerante a todos estos desafios presentados.

	\subsubsection {Ciclo de Clasificacion de Imágenes}
	  \begin{itemize}
	    \item Conjunto de datos de entrada: El conjunto de datos de entrada es un conjunto de N imágenes, cada una etiquetada con una de las K diferentes categorias.  
	    \item Aprendizaje: En base al conjunto de datos de entrenamiento, el sistema debe aprender como identificar las caracteristicas de cada categoria para asi establecer un modelo clasificador.
	    \item Evaluación: Finalmente se evalua la calidad del modelo clasificador haciendo que prediga las etiquetas para un conjunto (de prueba) nuevo de imagenes que no habia visto antes, comparando las 
	    etiquetas correctas con las etiquetas predecidas por el clasificador se puede establecer una metrica de calidad, intuitivamente se espera que las etiquetas predecidas coincidan en la mayoria
	    de los casos con las etiquetas correctas.
	  \end{itemize}
      
    \subsection{Clasificación Lineal}
      Este enfoque tiene 2 componentes principales que luego seran extendidos a las Redes Neuronales: Una funcion de puntuación que asigna un puntaje de pertenencia de cada instancia a cada categoria, 
      y una función de pérdida que cuantifica la coincidencia entre los puntajes predecidos con los puntajes correctos.
      Este problema se reduce a un problema de optimización donde se requiere minimizar la función de pérdida con respecto a la función de puntuación.

      \subsubsection{Función de Puntuación}
	El primer componente desde este enfoque es definir una función de  puntuación que mapee el valor de los pixeles de una imagen a un puntaje de confianza para cada categoría.
	Asumiendo que la entrada de la funcion son imagenes, cada una con una etiqueta de categoria dentro de las K categorias, la salida debe ser un valor de confianza de esa imagen 
	para cada una de las K categorias.
	Por ejemplo si tenemos 100 imagenes de 3 canales, de 32*32 pixeles y 10 categorias, definimos una funcion de puntuacion que toma entradas..

	\paragraph{Funcion Lineal:} 
	  f(xi,W,b)=Wxi+b
	  xi es una imagen representada por sus pixeles, W es un vector de pesos y b es un termino de regularizacion

      \subsubsection{Función de Pérdida}
	En la funcion lineal se puede observar que esta parametrizada por un conjunto de pesos.
	No se tiene control sobre los valores de los pixeles pero si se puede controlar el vector de pesos, de forma tal que el valor predecido sea consistente con el valor correcto. 
	La funcion de perdida pretende medir el error entre el valor predecido y el valor correcto, intutivamente la perdida sera mayor si el clasificador predice de forma erronea y 
	menor si lo hace de forma correcta.
	La idea es minimizar la funcion de perdida adaptando los valores de los pesos.

    \subsection{Optimización}
      El objetivo de la optimización es encontrar el vector de pesos W que minimice la funcion de perdida.

    \subsection{Gradiente} 
      La estrategia de optimización mas utilizada para este tipo de problemas es la de seguir la dirección del gradiente (también llamado derivadas) de la función de pérdida.
      En este caso que la función toma como entrada un vector de números, se aplican las derivadas parciales y el gradiente es el vector resultante de calcular las derivadas parciales
      en cada dimensión.

      \subsubsection{Descenso por el gradiente}
	La idea de principal de este metodo es el refinamiento iterativo, se evalua el resultado del calculo del gradiente y se actualizan los parámetros repetidamente, 
	toma un hiperparametro llamado tasa de aprendizaje que define el tamaño de cada paso en la iteración.
	Este es el método mas utilizado para optimizar funciones de pérdida en las Redes Neuronales. 

      \subsubsection{Descenso por el gradiente estocástico:}
	Un problema recurrente en el aprendizaje automático es que grandes conjuntos de entrenamiento son necesarios para una buena generalización, 
	pero grandes conjuntos de entrenamiento también son más costosos desde el punto de vista computacional.
	En aplicaciones de gran escala, el conjunto de entrenamiento puede ser del orden de los millones de ejemplos, por lo que computar la funcion de 
	pérdida completa sobre todo el conjunto para actualizar un solo parámetro seria algo impracticable.
	Un enfoque común que se aplica a este problema es computar el gradiente sobre pequeños lotes del conjunto de entrenamiento, 
	que permite lograr una buena aproximación al objetivo completo con una convergencia mucho mas rapida.


      \subsubsection{Otras formas de optimizacion}
	Existen otros metodos de optimizacion que trabajan de forma similar al descenso por el gradiente, ADAM, LBFGS,RMSProp etc. 
	\FIXME{DETALLAR} 
	
    \subsection{Retropropagación del Error}
      \url{http://cs231n.github.io/optimization-2/}
      Retropropagación (en inglés Backpropagation) una forma  de computar los gradientes de expresiones mediante la aplicacion recursiva de la regla de la cadena.
      El ciclo consta de 2 fases, propagación y luego actualizacion de parámetros. Cuando ingresan los parámetro a la función se calcula el resultado final, y se lo compara con el resultado 
      deseado, aplicando la función de pérdida se calcula el error, mediante el metodo de optimizacion se define el gradiente para luego realizar la retropropagación en la función hasta 
      actualizar los parametros.

    \subsection{Construyendo un algoritmo de aprendizaje automático}
      Casi todos los algoritmos de aprendizaje profundo pueden ser descritos como casos particulares de una receta bastante simple: 
      combinar una especificación de un conjunto de datos, una función de pérdida, un procedimiento de optimización y un modelo.
      Al darnos cuenta de que podemos reemplazar cualquiera de estos componentes en gran medida independientemente de los otros, podemos obtener una gran variedad de algoritmos.
      La función de costos incluye típicamente al menos un término que hace que el proceso de aprendizaje realice una estimación estadística. También puede incluir términos adicionales, 
      como los términos de regularización. Esto todavía permite la optimización de forma cerrada. 
      Si cambiamos el modelo para que no sea lineal, entonces la mayoría de las funciones de pérdida ya no pueden ser optimizadas en forma cerrada. 
      Esto nos obliga a elegir un procedimiento iterativo de optimización numérica, como el descenso por el gradiente.
    
    \section{Redes Neuronales Artificiales}
      Combinacion lineal de funciones no lineales
 \iffalse
      An artificial neural network (ANN) learning algorithm, usually called "neural network" (NN), is a learning algorithm that is inspired by the structure and functional aspects 
      of biological neural networks. Computations are structured in terms of an interconnected group of artificial neurons, processing information using a connectionist approach 
      to computation. Modern neural networks are non-linear statistical data modeling tools. They are usually used to model complex relationships between inputs and outputs, 
      to find patterns in data, or to capture the statistical structure in an unknown joint probability distribution between observed variables.
      
 \fi
 \FIXME{Ver Bishop Cap 5 pag 242}
      Un algoritmo de aprendizaje de red neuronal artificial (ANN), usualmente llamado "red neuronal" (NN), es un algoritmo de aprendizaje que se inspira en la estructura y aspectos funcionales
      De redes neuronales biológicas. Los cálculos se estructuran en términos de un grupo interconectado de neuronas artificiales, procesando la información utilizando un enfoque conexionista
      A la computación. Las redes neuronales modernas son herramientas no lineales de modelado de datos estadísticos. Usualmente se usan para modelar relaciones complejas entre entradas y salidas,
      Para encontrar patrones en los datos, o para capturar la estructura estadística en una distribución de probabilidad conjunta desconocida entre las variables observadas.
      
      \subsection{Aprendizaje basado en el Gradiente}
	El diseño y entrenamiento de una red neural no es muy diferente de la formación de cualquier otro modelo de aprendizaje automático con descenso por el gradiente.
	La diferencia más grande entre los modelos lineales y las redes neuronales es que la no linealidad de una red neural hace que las funciones de pérdida 
	más interesantes se vuelvan no convexas. Esto significa que las redes neuronales suelen ser entrenadas mediante el uso de optimizadores iterativos basados ​​en gradientes 
	que simplemente minimizan la función de costo, en lugar de los solucionadores de ecuaciones lineales usados ​​para entrenar modelos de regresión lineal o los algoritmos de optimización 
	convexa con garantías de convergencia global usadas para entrenar Regresión logística o SVMs.
      
      \subsection{Analisis comparativo con otras técnicas de Aprendizaje Automático}
	\paragraph {Ventajas}
	  \begin{itemize}
	    \item Bueno para variables de entrada continuas
	    \item Aproximadores generales de funciones continuas
	    \item Altamente no lineales
	    \item Aprende funciones caracteristicas
	    \item Bueno para usar en dominios continuos con poco conocimiento:
	      \subitem Cuando no se conocen buenas caracteristicas
	      \subitem No se conoce la forma de un buen modelo funcional
	  \end{itemize}
	\paragraph {Desventajas}
	  \begin{itemize}
	    \item Los resultados intermedios no son interpretables, al resultado final se los considera como proveniente de una caja negra.
	    \item El aprendizaje es lento
	    \item Para lograr una buena generalizacion puede requerir muchos datos
	  \end{itemize}

      \subsection {Historia de las Redes Neuronales Artificiales}
      
      \subsection {Motivación biológica} 
	El area de las redes neuronales artificiales fue originalmente insipirada por el objetivo de modelar los sistemas neuronales biológicos, 
	pero luego fue divergiendo
	y convirtiendose en una tarea de Ingenieria para obtener buenos resultados dentro del area de Aprendizaje automatico.
	Dendritas, input axones, sinapsis y output.
	IMAGEN DE ANALOGIA

      \subsection {Neurona artificial Unidad}
	Consta de un vector de entrada, un vector de pesos y una función de activación no lineal
	En una neurona se realiza el producto punto entre el vector de entrada, y su vector de pesos, le suma el sesgo y aplica la funcion de no linearidad.
	Una unica neurona puede ser utilizada para implementar un clasificador binario.

      \subsection {Funciones de Activacion comunmente utilizadas}
	Toda funcion de activacion toma un unico numero como entrada, realiza un operacion matematica predefinida, no lineal y devuelve el resultado obtenido.
	Algunos ejemplos de funciones que se utilizan:
	\begin{itemize}
	  \item Sigmoid:
	  \item Tangente hiperbolica
	  \item ReLU:max(0,x)
	\end{itemize}

    \subsection {Arquitectura de las Redes Neuronales}
      Organización por capas: Las redes neuronales se pueden modelar como un conjunto de neuronas conectadas en un grafo aciclico, que se suelen organizar por capas, las neuronas de una capa
      se conectan con neuronas de sus capas adjacentes pero nunca se conectan 2 neuronas de una misma capa.
      Toda red neuronal tiene una capa de entrada, una capa de salida y un numero determinado de capas ocultas, que pueden ser de distintos tipos.
      Una de las principales razones por la cual las redes neuronales estan organizadas en capas, es que este tipo de estructura permite evaluar una red, muy simple y eficientemente realizando
      operaciones matriciales vectoriales, una red neuronal puede ser pensada como una serie de multiplicaciones de matrices entrelazadas con funciones de activaciones no lineales.
      Las redes neuronales utilizadas en la actualidad tienen alrededor de 100 millones de parametros distribuidos entre 10-20 capas.
      Al definir la arquitectura de la red, se forma lo que seria una funcion de puntuacion, una red neuronal realiza una combinacion lineal de funciones no lineales. 

    \subsection {Preprocesamiento de datos}
	Restarle la media a cada caracteristica \\
	Normalizacion \\
	PCA: El algoritmo de análisis de componentes principales proporciona un medio de comprimir datos \\

    \paragraph {Inicializacion de los pesos}
      Error comun: Iniciar en 0.
      Inicializar con valores aleatorios cercanos a 0 

    \paragraph {Regularizacion: Dropout}


    \subsection {Entrenamiento}
      Consiste de 2 pasos: Paso hacia adelante, y paso de retroalimentacion
      \begin{enumerate}
      \item En el paso hacia adelante se evalua la red y se obtiene el resultado de salida, el cual se mide el error, se calcula el gradiente para luego aplicar el paso de retroalimentacion
	\item En el paso de retroalimentacion se ajustan los pesos internos de la red en base al resultado del gradiente.
      \end{enumerate}
      Esto se realiza iterativamente una cantidad predefinida de veces.

  \section {Aprendizaje Profundo}
    La caída de los precios de hardware y el desarrollo de GPUs para uso personal en los últimos años han contribuido al desarrollo del concepto de aprendizaje profundo (Deep Learning en ingles)
    que consiste de múltiples capas ocultas en una red neuronal artificial. Este enfoque trata de modelar la forma en que el cerebro humano procesa luz y sonido en visión y audición.
    Algunas aplicaciones exitosas del aprendizaje profundo son la visión por computadora y el reconocimiento del habla.
    \subsection {Motivación}
      Los algoritmos simples de aprendizaje automático funcionan muy bien en una amplia variedad de problemas importantes. 
      Sin embargo, no han logrado resolver los problemas centrales de Inteligencia Artificial, como reconocer el habla o reconocer objetos. 
      El desarrollo del aprendizaje profundo fue motivado en parte por el fracaso de los algoritmos tradicionales para generalizar bien en tales tareas de Inteligencia Artificial.
      El desafío de generalizar a nuevos ejemplos se vuelve más difícil cuando se trabaja con datos de gran dimensión y los mecanismos utilizados para lograr la generalización 
      en el aprendizaje  automático tradicional son insuficientes para aprender funciones complicadas en espacios de alta dimensión. 
      Tales espacios también suelen imponer altos costos computacionales. El aprendizaje profundo fue diseñado para superar estos y otros obstáculos.

  \section {Redes Neuronales Convolucionales}
    Las redes neuronales convolucionales (CNN) son muy similares a las redes neuronales antes vista, con la diferencia en que la arquitectura de una red neuronal convolucional asume explicitamente
    que el conjunto de entrada son imagenes, lo que le permite codificar ciertas propiedades dentro de la arquitectura. 
    Estan inspiradas en las redes neuronales tradicionales, incorporando operaciones no-lineales de manipulación de imágenes.

    \subsection {Historia de las Redes Neuronales Convolucionales}

    \subsection {Arquitectura de una red neuronal convolucional}
      En las redes neuronales convolucionales, las neuronas dentro de una capa se organizan en 3 dimensiones: alto, ancho y profundidad.
      Cada capa acepta un volumen de 3 dimensiones como entrada y lo transforma en un volumen de salida de 3 dimensiones a traves de una función diferenciable.
      Algunas capas pueden tener o no parámetros, al igual que hiperparámetros. La entrada y salida de cada una de estas capas son conjuntos de arreglos llamados “mapas de features”.
      En el caso mas simple de arquitectura, la red transforma el volumen de una imagen de entrada en un volumen de salida, conteniendo los puntajes de cada clase para el problema de clasificacion.
      Tipicamente, las CNNs suelen además organizarse por etapas, cada etapa consiste de una capa convolucional, una no lineal y una de agrupamiento. 
      A continuación se detallan estos tipos de capas.

    \subsection {Tipos de Capas}
      \subsubsection{Capa Convolucional} 
	Los parametros consisten en un conjunto de filtros aprendibles. Cada filtro el pequeño espacialmente(alto y ancho) pero se extiende sobre toda la profundidad del volumen de entrada.
	Durante el paso hacia adelante, se desliza o convoluciona el filtro atraves del alto y ancho del volumen de entrada y se computa el producto punto entre los valores del filtro y los valores
	del volumen de entrada. A medida que se va deslizando el filtro sobre el ancho y el alto del volumen de entrada, se va generando un mapa de activacion de 2 dimensiones que contiene los 
	valores de respuesta de ese filtro en cada posicion espacial.
	Intuitivamente, la red aprenderá los filtros que se activan cuando ven algún tipo de característica visual como un borde de cierta orientación o una mancha de algún color en la 
	primera capa, o eventualmente panal entero o patrones de rueda en las capas más altas de la red. Dado que tendremos un conjunto de filtros en cada capa Convolucional, 
	y cada uno de ellos producirá un mapa de activación bidimensional separado, estos se apilaran a lo largo de la dimensión de profundidad para producir el volumen de salida.

	Retropropagación: El paso hacia atrás para una operación de convolución (tanto para los datos como para los pesos) es también una convolución (pero con filtros espacialmente invertidos).

      \subsubsection{Capa de Agrupamiento} 
	Su función es reducir progresivamente el tamaño espacial de la representación para reducir la cantidad de parámetros y de cálculo en la red, y por lo tanto también para controlar
	el Overfitting. La capa de agrupamiento funciona independientemente en cada segmento de profundidad de la entrada y la redimensiona espacialmente, utilizando la operación de máximo, 
	tambien se suele utilizar la operacion de promedio o la norma L2.

	Retroalimentacion
	el paso hacia atrás para una operación maximo tiene una interpretación sencilla, ya que sólo encamina el gradiente a la entrada que tenía el valor más alto en el paso hacia
	adelante. Por lo tanto, durante el paso hacia adelante de una capa de agrupamiento es común realizar un seguimiento del índice de la activación máxima de manera que 
	el enrutamiento de gradiente es eficiente durante la retropropagación.

      \subsubsection{Capas No Lineales}
	Estas capas son las encargadas de aplicar una función de activación no lineal, las principales son:
	\paragraph{ReLU} Las unidades lineales rectificadas usan la función de activación g (z) = max {0, z}. 
	Las unidades lineales rectificadas son fáciles de optimizar porque son tan similares a las unidades lineales. 
	La única diferencia entre una unidad lineal y una unidad lineal rectificada es que una unidad lineal rectificada da salida a cero a través de la mitad de su dominio. 
	Esto hace que las derivadas a través de una unidad lineal rectificada permanezcan grandes siempre que la unidad esté activa.
	Los gradientes no sólo son grandes sino también consistentes.
	Existen varias generalizaciones de unidades lineales rectificadas. La mayoría de estas generalizaciones se comportan de forma comparable a las unidades lineales rectificadas
	y, en ocasiones, tienen un mejor desempeño. Un inconveniente para las unidades lineales rectificadas es que no pueden aprender a través de métodos basados ​​en 
	gradiente en ejemplos para los cuales su activación es cero. Una variedad de generalizaciones de unidades lineales rectificadas garantizan que reciben gradiente en 
	todas partes. Existen 3 generalizaciones sobre esta, que agregan un parámetro de regularización:
	  \subparagraph{Rectificacion por Valor Absoluto}
	  \subparagraph{Leaky ReLU} Agrega un parametro de regularizacion, fijandolo en un valor pequeño como por ejemplo 0.01.
	  \subparagraph{Parametric ReLU} Trata el parámetro de regularizacion como un parámetro aprendible.
	\paragraph{Maxout}
      
      \subsubsection{Capa Completamente Conectada} 
	Las neuronas entre dos capas adyacentes están completamente conectadas de a pares, pero las neuronas dentro de una sola capa no comparten conexiones.

    \subsection {Consideraciones computacionales}
      El cuello de botella más grande a tener en cuenta al construir arquitecturas ConvNet es el cuello de botella de memoria. 
      Muchas GPUs modernas tienen un límite de memoria de 3/4 / 6GB, con las mejores GPUs que tienen cerca de 12GB de memoria. 
      Hay tres fuentes principales de memoria para realizar un seguimiento:
      \begin{itemize}
	\item A partir de los tamaños de volumen intermedios: Éstos son el número crudo de activaciones en cada capa de la ConvNet, y también sus gradientes (de igual tamaño). Normalmente, la mayoría de las activaciones se encuentran en las capas anteriores de una ConvNet (es decir, primeras capas de convección). Estos se mantienen alrededor porque son necesarios para backpropagation, pero una implementación inteligente que ejecuta un ConvNet sólo en tiempo de prueba podría en principio reducir esto en una cantidad enorme, sólo almacenando las activaciones actuales en cualquier capa y descartando las activaciones anteriores en las capas de abajo .
	\item A partir de los tamaños de parámetro: Estos son los números que contienen los parámetros de red, sus gradientes durante la retropropagación y, comúnmente, también un caché de pasos si la optimización utiliza impulso, Adagrad o RMSProp. Por lo tanto, la memoria para almacenar el vector de parámetros solo debe ser multiplicada por un factor de al menos 3 o más.
	\item Cada implementación de CNN tiene que mantener memoria datos extras, como los lotes de datos de imagen, tal vez sus versiones aumentadas, etc.
	Una vez que tenga una estimación aproximada del número total de valores (para activaciones, gradientes y extra), el número debe convertirse a tamaño en GB. Tome el número de valores, multiplique por 4 para obtener el número bruto de bytes (ya que cada punto flotante es 4 bytes, o tal vez por 8 para doble precisión), y luego dividir por 1024 varias veces para obtener la cantidad de memoria en KB, MB, y finalmente GB. Si su red no encaja, una heurística común para "hacerla encajar" es disminuir el tamaño del lote, ya que la mayor parte de la memoria suele ser consumida por las activaciones.
      \end{itemize}


    \subsection {Casos de estudio de redes convolucionales famosas}
      \begin{itemize}
	\item AlexNet
	\item VGG
	\item Inception
	\item Resnet
      \end{itemize}

    \section {Reentrenamiento}
    STANFORD
      El reentranmiento (Finetuning en inglés) toma un modelo ya entrenado, adapta la arquitectura y retoma el entrenamiento partiendo desde los pesos del modelo ya entrenado.
      \paragraph{Modelos preentrenados}
	Debido a que una red neuronal convolucional moderna requiere entre 2 y 3 semanas para entrenarse, utilizando multiples GPUs para el conjunto de datos ImageNet, es comun ver que gente
	publica sus Redes ya entrenadas para el beneficio de otras personas que lo pueden usar para hacer finetuning.
      \paragraph{Como y cuando hacer Reentrenamiento}
	¿Cómo decidir qué tipo de transferencia de aprendizaje debe realizar en un nuevo conjunto de datos? Esta es una función de varios factores, pero los dos más importantes son el 
	tamaño del nuevo conjunto de datos (pequeño o grande), y su similitud con el conjunto de datos original (por ejemplo ImageNet-como en términos de contenido de imágenes y las clases,
	O muy diferentes, tales como imágenes de microscopio). Teniendo en cuenta que las características de CNN son más genéricas en capas tempranas y más específicas del conjunto de datos
	originales en capas posteriores, aquí hay algunas reglas comunes para navegar por los 4 escenarios principales:
	\begin{itemize}
	  \item El nuevo conjunto de datos es pequeño y similar al conjunto de datos original. Dado que los datos son pequeños, no es una buena idea afinar la red convolucional debido a las 
	  preocupaciones excesivas. Dado que los datos son similares a los datos originales, esperamos que las características de mayor nivel en la red convolucional sean relevantes para este
	  conjunto de datos. Por lo tanto, la mejor idea podría ser la de formar un clasificador lineal utilizando las caracteristicas extraidas en la ultima capa de la red.
	  \item El nuevo conjunto de datos es grande y similar al conjunto de datos original. Dado que tenemos más datos, podemos tener más confianza de que no superaremos si intentáramos 
	  ajustar a través de la red completa.
	  \item El nuevo conjunto de datos es pequeño pero muy diferente del conjunto de datos original. Dado que los datos son pequeños, lo más probable es que sólo entrenen un clasificador 
	  lineal. Dado que el conjunto de datos es muy diferente, puede que no sea mejor entrenar al clasificador en la parte superior de la red, que contiene más características específicas
	  de conjunto de datos. En su lugar, podría funcionar mejor para entrenar el clasificador SVM de las activaciones en algún lugar anterior en la red.
	  \item El nuevo conjunto de datos es grande y muy diferente del conjunto de datos original. Dado que el conjunto de datos es muy grande, podemos esperar que podamos permitirnos 
	  entrenar a una red convolucional desde cero. Sin embargo, en la práctica es muy a menudo todavía beneficioso para inicializar con pesos de un modelo pre-entrenado. 
	  En este caso, tendríamos suficientes datos y confianza para afinar a través de toda la red.
	\end{itemize}
     \section {Otros conceptos relevantes}
	\subsubsection{Matriz de Gramm}

\chapter{Algoritmo de Transferencia de estilo}
    \section{Introduccion}
      En lo que al arte respecta, los humanos han desarrollado la capacidad de crear experiencias visuales únicas componiendo una compleja interacción entre el contenido y el estilo de una imagen.
    Sin ir mas lejos, las bases algoritmicas de este proceso se desconocen y no existen sistemas artificiales que con capacidades similares. Sin embargo, en otras areas fundamentales
    de la percepcion visual como el reconocimiento de objetos y rostros recientemente se ha alcanzado precisión cercana a la de un humano, utilizando modelos de redes neuronales profundas. 
    Aquí presentamos un sistema artificial basado en una Red Neural Profunda que crea imágenes artísticas de alta calidad perceptiva. El sistema utiliza representaciones neuronales 
    para separar y recombinar el contenido y el estilo de imágenes arbitrarias, proporcionando un algoritmo para la creación de imágenes artísticas.

    \section{Sintesis}
      Cuando las Redes Neuronales Convolucionales (CNNs) son entrenadas para reconocimiento de objetos, desarrollan una representacion de la imagen que hace que la información 
      del objeto sea cada vez más explícita a lo largo de la jerarquia de las capas de la red.Por lo tanto, a lo largo de la jerarquía de procesamiento de la red, 
      la imagen de entrada se transforma en representaciones que cada vez más se preocupan por el contenido real de la imagen en lugar del valor de sus píxeles detallados. 
      Podemos visualizar directamente la información que cada capa contiene sobre la imagen de entrada, reconstruyendo la imagen solo a partir de los mapas de caracteristicas
      de esa capa. Las capas más altas de la red capturan el contenido de alto nivel en términos de objetos y su ordenamiento en la imagen pero no se limitan a los valores de cada 
      pixel. En  cambio, las reconstrucciones de las capas inferiores simplemente pretenden reproducir los valores exactos de píxeles de la imagen original y algunas formas
      basicas como lineas o curvas. Por lo tanto, tomaremos a los mapas de características en las capas superiores de la red como el contenido representado.
      Para obtener la representacion del estilo de la imagen de entrada, se usa un espacio de caracteristicas originalmente diseñado para capturar información de texturas.
      Este espacio de caracteristicas esta construido sobre las respuestas de los filtros de cada capa de la red. Consiste en la correlación entre diferentes respuestas de los filtros.
      Incluyendo las correlaciones de multiples capas, se obtiene una representacion que captura información de la textura pero no del ordenamiento global de la imagen.
      Al reconstruir las imagenes a partir de las representaciones obtenidas, se puede observar que producen una version texturizada de la imagen que captura su 
      apariencia general en terminos de colores y estructuras localizadas, a estas representaciones las llamaremos representaciones de estilo.
      El principal descubrimiento de este articulo es que la representacion del estilo y el contenido de una imagen pueden ser separables con una Red Neuronal Convolucional entrenada 
      para el reconocimiento de objetos. De esta forma, al manipularse independientemente se pueden generar una nueva imagen desde 2 imagenes de entradas distintas, simultaneamente se corresponda con la representacion
      del contenido de una imagen y la respresentacion del estilo de la otra.

    \section{Metodos}
      Los resultados exhibidos fueron obtenidos utilizando la red VGG-19, de disponibilidad publica.
      Generalmente, cada capa de la red define un banco de filtros no lineal cuya complejidad aumenta con la posición de la capa en la red.
      Para visualizar la información de la imagen codificada en diferentes capas de la jerarquía se realiza descenso gradiente en una imagen de ruido blanco 
      para encontrar otra imagen que coincida con las características de respuesta de la imagen original.
      Funcion Perdida del Contenido ...
      Sobre las respuestas de la CNN en cada capa de la red construimos una representación de estilo que calcula las correlaciones entre las diferentes respuestas de los filtros.
      Estas correlaciones de las caracteristicas estan dadas por la matriz de Gram ...
      Para generar una textura que coincida con el estilo de una imagen dada, utilizamos el descenso de gradiente de una imagen de ruido blanco para encontrar otra imagen que coincida 
      con la representación de estilo de la imagen original. Esto se hace minimizando la distancia media cuadrada entre las entradas de la matriz de Gram de la imagen 
      original y la matriz de Gram de la imagen a generar.
      Funcion de Perdida del Estilo ...
      \FIXME{AGREGAR FORMULA}
      Para generar las imágenes que mezclan el contenido de una fotografía con el estilo de una obra de arte conjuntamente minimizamos la distancia de una imagen de ruido blanco 
      de la representación de contenido de la fotografía en una capa de la red y la representación de estilo de la obra de arte en un número de capas de la CNN.
      Funcion de Perdida total ...
      \FIXME{AGREGAR FORMULA}
    
     
\chapter{Descripción del problema y solución propuesto}
  \section{Descripción del problema}
    Basado en el algoritmo de transferencia de estilo se pueden obtener resultados muy interesantes, sin embargo es necesario definir una serie de hiperparametros,
    que necesita el algoritmo para poder ejecutarse. El criterio de elección de estos hiperparámetros termina siendo muy influyente en el resultado final. 
    Los principales hiperparametros a definir son:
    \begin{itemize}
      \item Numero de iteraciones que se ejecutará el optimizador.
      \item Modelo de Red Neuronal Convolucional preentrenada que se utilizará (existen una variedad de CNN presentadas anteriormente) junto con las capas que se utilizaran de la 
      respectiva red tanto para calcular el estilo como el contenido.
      \item Imagen desde la cual comenzar la optimización, es posible comenzar desde una imagen de ruido, desde la imagen de contenido.
      \item Método de optimización a utilizar.
    \end{itemize}

    Además, para poder realizar una comparación entre los distintos resultados generados por el algoritmo, es necesario establecer una métrica.
    
  \section{Algoritmo de Reconocimiento de estilo}
    \subsection{Introduccion}
      Las imagenes pintadas por humanos suelen tener un significado y el estilo visual de la misma tiene un papel significativo en cómo se ve, por lo que comprender
      el estilo es crucial para poder comprender el significado que la imagen intenta transmitir, sin embargo el estilo no ha recibido  mucha atención en el area de investigación de visión por computadoras. 
      Aunque es simple para los observadores humanos, el estilo visual es un concepto difícil de definir rigurosamente ya que involucra el contexto historico del arte en ese momento.
      Encontramos que las características aprendidas en una CNN funcionan muy bien para esta tarea. Esto es sorprendente por varias razones: Las caracteristicas aprendidas
      fueron entrenadas en categorias de clases de objetos (Imagenet), y muchos estilos parecieran ser principalmente definidos por las elecciones de colores, aunque
      las caracteristicas de las CNN, superan comodamente a las caracteristicas de los histogramas de colores. Esto lleva a unas de las conclusiones de este trabajo:
      Las caracteristicas de nivel medio para los conjuntos de datos de objetos son genericos para el reconocimiento de estilo, y las de nivel superior para las caracteristicas
      mas manuales.
      Se compararon los predictores obtenidos con observadores humanos y esencialmente se obtuvieron niveles de precision similares.
    \subsection{Algoritmo de Aprendizaje}
      El algoritmo aprende a clasificar las imágenes nuevas según su estilo, utilizando las etiquetas provistas en el conjunto de entrenamiento.
      Debido a que los conjuntos de datos que tratamos son bastante grandes y algunas de las características son de grandes dimensiónes, consideramos sólo clasificadores lineales, 
      dependiendo de características sofisticadas para proporcionar robustez. Utilizamos una implementación de fuente abierta de Descenso de Gradiente Estocástico con adaptación
      del Subgradiente. El proceso de aprendizaje optimiza la función ...
    \subsection{Caracteristicas de las imagenes}
	Para clasificar estilos, debemos elegir características de imagen apropiadas. Nosotros hipotetizamos que el estilo de imagen puede estar relacionado con muchas características diferentes, 
	incluyendo estadísticas de bajo nivel, las opciones de color, la composición y el contenido. Por lo tanto, probamos características que incorporan estos diferentes elementos, incluyendo características de la 
	literatura de reconocimiento de objetos. Evaluamos el rendimiento de una sola función, así como la segunda etapa de fusión de múltiples características.
	Las principales caracteristicas evaluadas fueron:
	\begin{itemize}
	 \item Histogramas de colores
	 \item Descriptores GIST
	 \item Caracteristicas extraidas de una CNN
	\end{itemize}
	Se encontro que las caracteristicas extraidas de una CNN son las que mejor precisión proveen a la hora de reconocer estilos.

  \section{Finetuning para reconocimiento de estilos}
    Basado en los resultados propuestos en el articulo antes mencionado, se realizo un finetuning sobre la red AlexNet, por cuestiones de simplicidad, utilizando
    el conjunto de datos Wikipaintings, para los 10 estilos que mas datos provee.
  
  \section{Solución propuesta}
    En la solución propuesta en este trabajo se plantea poder definir automáticamente el número de iteraciones que debe ejecutarse el algoritmo hasta lograr obtener un resultado.
    El resto de los hiperparámetros permanecen predefinidos a mano, excepto la imagen de la cual comenzar que influye notablemente en la cantidad de iteraciones que debe realizar el 
    algoritmo para obtener un resultado aceptable.
    La solución consta de 2 módulos principales: un módulo encargado de la generación de la imagen (a partir de una imagen de contenido y otra de estilo) y otro módulo encargado de 
    evaluar.
    \subsection{Módulo de generación de imagenes}
      Existen una gran variedad de implementaciónes de código abierto que implementan el algoritmo de transferencia de estilo. La que se decidió utilizar fue la de Justin Jhonson (\url{https://github.com/jcjohnson/neural-style}),
      la cual posee el mayor grado de aceptación en la industria.
      La principal tecnología utilizada en esta implementación es el Framework Torch, que utiliza como lenguaje de programación a Lua.
    \subsection{Módulo de evaluación de imagenes}
      Para poder establecer una métrica de comparación, se realizó finetuning sobre AlexNet, con el conjunto de datos de Wikipaintings, para que la red reentrenada aprenda a reconocer
      el estilo de una obra de arte para los 10 estilos que mas datos provee, obteniendo una precision del 92%.
      De esta forma se van realizando evaluaciones del resultado obtenido por el algoritmo generador contra la predicción que realiza el modelo reentrenado para el reconocimiento de estilos.
      La implementación de este módulo fue realizada principalmente en Python, utilizando el Framework Caffe y la libreria OpenCV.
    \subsection{Criterio de Selección}
      El criterio de selección para elegir la imagen óptima fue el siguiente:
      Dado que el estilo de la imagen resultante no siempre termina siendo el mismo estilo de la imagen provista para transferir el estilo, el estilo objetivo se definió como el estilo
      que tiene asignada una mayor probabilidad de reconocimiento luego de 1000 iteraciones.
      Una vez definido el estilo objetivo, se definen los intervalos donde el puntaje obtenido por el estilo objetivo supera al puntaje del resto de los estilos y se toma el punto medio.

    \subsection{Conjunto de datos}
      El conjunto de datos utilizado para en este trabajo es el de Wikipaintings
    
      
\chapter{Experimentos}
\chapter{Conclusiones, Perspectivas y trabajos a futuro}
  \section{Conclusiones}
  \section{Trabajos a futuro}
    Se podría realizar una especie de predefinición del numero de iteraciones que requiere cada estilo, ejecutando el algoritmo una gran cantidad de veces y definiendo este valor 
    estadisticamente, aunque esto puede llegar a no funcionar correctamente en todos los casos ya que dependiendo de la imagen de contenido, el estilo objetivo podria variar.
\printindex
\end{document}